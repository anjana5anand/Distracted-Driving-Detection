{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2e1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boundaries_from_labels(labels, background_class=0):\n",
    "    B, T = labels.shape\n",
    "    boundaries = torch.zeros(B, 2)\n",
    "\n",
    "    for b in range(B):\n",
    "        action_mask = labels[b] != background_class\n",
    "        indices = action_mask.nonzero(as_tuple=True)[0]\n",
    "        # print(action_mask, indices)\n",
    "        if len(indices) > 0:\n",
    "            start = indices[0].item()\n",
    "            end = indices[-1].item()\n",
    "            # # Normalize\n",
    "            boundaries[b, 0] = start #/ T\n",
    "            boundaries[b, 1] = (end + 1) #/ T  # +1 to make end exclusive\n",
    "        else:\n",
    "            # If only background: set to [0, 0]\n",
    "            boundaries[b, :] = 0.0\n",
    "\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82daea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = np.load('/media/viplab/DATADRIVE1/driver_action_recognition/pose_resnet_features_multi/A1/train/user_id_13522_5/Rear_view_user_id_13522_NoAudio_5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aba6547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2545, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff751ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/viplab/Storage1/driver_action_recognition/raw_features/A1/train\n",
      "uuuu user_id_70176_7\n",
      "1 Dashboard_user_id_70176_NoAudio_7\n",
      "k user_id_70176_7/Dashboard_user_id_70176_NoAudio_7\n",
      "uuuu user_id_69039_5\n",
      "1 Dashboard_user_id_69039_NoAudio_5\n",
      "k user_id_69039_5/Dashboard_user_id_69039_NoAudio_5\n",
      "uuuu user_id_16080_5\n",
      "1 Dashboard_user_id_16080_NoAudio_5\n",
      "k user_id_16080_5/Dashboard_user_id_16080_NoAudio_5\n",
      "uuuu user_id_61962_5\n",
      "1 Dashboard_user_id_61962_NoAudio_5\n",
      "k user_id_61962_5/Dashboard_user_id_61962_NoAudio_5\n",
      "uuuu user_id_16700_5\n",
      "1 Dashboard_user_id_16700_NoAudio_5\n",
      "k user_id_16700_5/Dashboard_user_id_16700_NoAudio_5\n",
      "uuuu user_id_59014_7\n",
      "1 Dashboard_user_id_59014_NoAudio_7\n",
      "k user_id_59014_7/Dashboard_user_id_59014_NoAudio_7\n",
      "uuuu user_id_53307_5\n",
      "1 Dashboard_user_id_53307_NoAudio_5\n",
      "k user_id_53307_5/Dashboard_user_id_53307_NoAudio_5\n",
      "uuuu user_id_50921_7\n",
      "1 Dashboard_user_id_50921_NoAudio_7\n",
      "k user_id_50921_7/Dashboard_user_id_50921_NoAudio_7\n",
      "uuuu user_id_52046_5\n",
      "1 Dashboard_user_id_52046_NoAudio_5\n",
      "k user_id_52046_5/Dashboard_user_id_52046_NoAudio_5\n",
      "uuuu user_id_25077_7\n",
      "1 Dashboard_user_id_25077_NoAudio_7\n",
      "k user_id_25077_7/Dashboard_user_id_25077_NoAudio_7\n",
      "uuuu user_id_87903_5\n",
      "1 Dashboard_user_id_87903_NoAudio_5\n",
      "k user_id_87903_5/Dashboard_user_id_87903_NoAudio_5\n",
      "uuuu user_id_46844_5\n",
      "1 Dashboard_user_id_46844_NoAudio_5\n",
      "k user_id_46844_5/Dashboard_user_id_46844_NoAudio_5\n",
      "uuuu user_id_38159_7\n",
      "1 Dashboard_user_id_38159_NoAudio_7\n",
      "k user_id_38159_7/Dashboard_user_id_38159_NoAudio_7\n",
      "uuuu user_id_41850_5\n",
      "1 Dashboard_user_id_41850_NoAudio_5\n",
      "k user_id_41850_5/Dashboard_user_id_41850_NoAudio_5\n",
      "uuuu user_id_46141_7\n",
      "1 Dashboard_user_id_46141_NoAudio_7\n",
      "k user_id_46141_7/Dashboard_user_id_46141_NoAudio_7\n",
      "uuuu user_id_38479_7\n",
      "1 Dashboard_user_id_38479_NoAudio_7\n",
      "k user_id_38479_7/Dashboard_user_id_38479_NoAudio_7\n",
      "uuuu user_id_63764_7\n",
      "1 Dashboard_user_id_63764_NoAudio_7\n",
      "k user_id_63764_7/Dashboard_user_id_63764_NoAudio_7\n",
      "uuuu user_id_22640_5\n",
      "1 Dashboard_user_id_22640_NoAudio_5\n",
      "k user_id_22640_5/Dashboard_user_id_22640_NoAudio_5\n",
      "uuuu user_id_47158_5\n",
      "1 Dashboard_user_id_47158_NoAudio_5\n",
      "k user_id_47158_5/Dashboard_user_id_47158_NoAudio_5\n",
      "uuuu user_id_50347_7\n",
      "1 Dashboard_user_id_50347_NoAudio_7\n",
      "k user_id_50347_7/Dashboard_user_id_50347_NoAudio_7\n",
      "uuuu user_id_35418_5\n",
      "1 Dashboard_user_id_35418_NoAudio_5\n",
      "k user_id_35418_5/Dashboard_user_id_35418_NoAudio_5\n",
      "uuuu user_id_71720_7\n",
      "1 Dashboard_user_id_71720_NoAudio_7\n",
      "k user_id_71720_7/Dashboard_user_id_71720_NoAudio_7\n",
      "uuuu user_id_25432_7\n",
      "1 Dashboard_user_id_25432_NoAudio_7\n",
      "k user_id_25432_7/Dashboard_user_id_25432_NoAudio_7\n",
      "uuuu user_id_59581_5\n",
      "1 Dashboard_user_id_59581_NoAudio_5\n",
      "k user_id_59581_5/Dashboard_user_id_59581_NoAudio_5\n",
      "uuuu user_id_63764_5\n",
      "1 Dashboard_user_id_63764_NoAudio_5\n",
      "k user_id_63764_5/Dashboard_user_id_63764_NoAudio_5\n",
      "uuuu user_id_42711_7\n",
      "1 Dashboard_user_id_42711_NoAudio_7\n",
      "k user_id_42711_7/Dashboard_user_id_42711_NoAudio_7\n",
      "uuuu user_id_38479_5\n",
      "1 Dashboard_user_id_38479_NoAudio_5\n",
      "k user_id_38479_5/Dashboard_user_id_38479_NoAudio_5\n",
      "uuuu user_id_50347_5\n",
      "1 Dashboard_user_id_50347_NoAudio_5\n",
      "k user_id_50347_5/Dashboard_user_id_50347_NoAudio_5\n",
      "uuuu user_id_86952_9\n",
      "1 Dashboard_user_id_86952_NoAudio_9\n",
      "k user_id_86952_9/Dashboard_user_id_86952_NoAudio_9\n",
      "uuuu user_id_93439_5\n",
      "1 Dashboard_user_id_93439_NoAudio_5\n",
      "k user_id_93439_5/Dashboard_user_id_93439_NoAudio_5\n",
      "uuuu user_id_53307_7\n",
      "1 Dashboard_user_id_53307_NoAudio_7\n",
      "k user_id_53307_7/Dashboard_user_id_53307_NoAudio_7\n",
      "uuuu user_id_50921_5\n",
      "1 Dashboard_user_id_50921_NoAudio_5\n",
      "k user_id_50921_5/Dashboard_user_id_50921_NoAudio_5\n",
      "uuuu user_id_70176_5\n",
      "1 Dashboard_user_id_70176_NoAudio_5\n",
      "k user_id_70176_5/Dashboard_user_id_70176_NoAudio_5\n",
      "uuuu user_id_46141_5\n",
      "1 Dashboard_user_id_46141_NoAudio_5\n",
      "k user_id_46141_5/Dashboard_user_id_46141_NoAudio_5\n",
      "uuuu user_id_83323_3\n",
      "1 Dashboard_user_id_83323_NoAudio_3\n",
      "k user_id_83323_3/Dashboard_user_id_83323_NoAudio_3\n",
      "uuuu user_id_60768_7\n",
      "1 Dashboard_user_id_60768_NoAudio_7\n",
      "k user_id_60768_7/Dashboard_user_id_60768_NoAudio_7\n",
      "uuuu user_id_60167_7\n",
      "1 Dashboard_user_id_60167_NoAudio_7\n",
      "k user_id_60167_7/Dashboard_user_id_60167_NoAudio_7\n",
      "uuuu user_id_16700_7\n",
      "1 Dashboard_user_id_16700_NoAudio_7\n",
      "k user_id_16700_7/Dashboard_user_id_16700_NoAudio_7\n",
      "uuuu user_id_57207_1\n",
      "1 Dashboard_user_id_57207_NoAudio_1\n",
      "k user_id_57207_1/Dashboard_user_id_57207_NoAudio_1\n",
      "uuuu user_id_39367_5\n",
      "1 Dashboard_user_id_39367_NoAudio_5\n",
      "k user_id_39367_5/Dashboard_user_id_39367_NoAudio_5\n",
      "uuuu user_id_61302_7\n",
      "1 Dashboard_user_id_61302_NoAudio_7\n",
      "k user_id_61302_7/Dashboard_user_id_61302_NoAudio_7\n",
      "uuuu user_id_31903_7\n",
      "1 Dashboard_user_id_31903_NoAudio_7\n",
      "k user_id_31903_7/Dashboard_user_id_31903_NoAudio_7\n",
      "uuuu user_id_78052_11\n",
      "1 Dashboard_user_id_78052_NoAudio_11\n",
      "k user_id_78052_11/Dashboard_user_id_78052_NoAudio_11\n",
      "uuuu user_id_22640_7\n",
      "1 Dashboard_user_id_22640_NoAudio_7\n",
      "k user_id_22640_7/Dashboard_user_id_22640_NoAudio_7\n",
      "uuuu user_id_33682_7\n",
      "1 Dashboard_user_id_33682_NoAudio_7\n",
      "k user_id_33682_7/Dashboard_user_id_33682_NoAudio_7\n",
      "uuuu user_id_93439_7\n",
      "1 Dashboard_user_id_93439_NoAudio_7\n",
      "k user_id_93439_7/Dashboard_user_id_93439_NoAudio_7\n",
      "uuuu user_id_60167_5\n",
      "1 Dashboard_user_id_60167_NoAudio_5\n",
      "k user_id_60167_5/Dashboard_user_id_60167_NoAudio_5\n",
      "uuuu user_id_28557_5\n",
      "1 Dashboard_user_id_28557_NoAudio_5\n",
      "k user_id_28557_5/Dashboard_user_id_28557_NoAudio_5\n",
      "uuuu user_id_40908_5\n",
      "1 Dashboard_user_id_40908_NoAudio_5\n",
      "k user_id_40908_5/Dashboard_user_id_40908_NoAudio_5\n",
      "uuuu user_id_61497_7\n",
      "1 Dashboard_user_id_61497_NoAudio_7\n",
      "k user_id_61497_7/Dashboard_user_id_61497_NoAudio_7\n",
      "uuuu user_id_14786_7\n",
      "1 Dashboard_user_id_14786_NoAudio_7\n",
      "k user_id_14786_7/Dashboard_user_id_14786_NoAudio_7\n",
      "uuuu user_id_72446_5\n",
      "1 Dashboard_user_id_72446_NoAudio_5\n",
      "k user_id_72446_5/Dashboard_user_id_72446_NoAudio_5\n",
      "uuuu user_id_38159_5\n",
      "1 Dashboard_user_id_38159_NoAudio_5\n",
      "k user_id_38159_5/Dashboard_user_id_38159_NoAudio_5\n",
      "uuuu user_id_64003_7\n",
      "1 Dashboard_user_id_64003_NoAudio_7\n",
      "k user_id_64003_7/Dashboard_user_id_64003_NoAudio_7\n",
      "uuuu user_id_59581_7\n",
      "1 Dashboard_user_id_59581_NoAudio_7\n",
      "k user_id_59581_7/Dashboard_user_id_59581_NoAudio_7\n",
      "uuuu user_id_40908_7\n",
      "1 Dashboard_user_id_40908_NoAudio_7\n",
      "k user_id_40908_7/Dashboard_user_id_40908_NoAudio_7\n",
      "uuuu user_id_13522_7\n",
      "1 Dashboard_user_id_13522_NoAudio_7\n",
      "k user_id_13522_7/Dashboard_user_id_13522_NoAudio_7\n",
      "uuuu user_id_79755_3\n",
      "1 Dashboard_user_id_79755_NoAudio_3\n",
      "k user_id_79755_3/Dashboard_user_id_79755_NoAudio_3\n",
      "uuuu user_id_52046_11\n",
      "1 Dashboard_user_id_52046_NoAudio_11\n",
      "k user_id_52046_11/Dashboard_user_id_52046_NoAudio_11\n",
      "uuuu user_id_30932_5\n",
      "1 Dashboard_user_id_30932_NoAudio_5\n",
      "k user_id_30932_5/Dashboard_user_id_30932_NoAudio_5\n",
      "uuuu user_id_14786_5\n",
      "1 Dashboard_user_id_14786_NoAudio_5\n",
      "k user_id_14786_5/Dashboard_user_id_14786_NoAudio_5\n",
      "uuuu user_id_79755_5\n",
      "1 Dashboard_user_id_79755_NoAudio_5\n",
      "k user_id_79755_5/Dashboard_user_id_79755_NoAudio_5\n",
      "uuuu user_id_83756_3\n",
      "1 Dashboard_user_id_83756_NoAudio_3\n",
      "k user_id_83756_3/Dashboard_user_id_83756_NoAudio_3\n",
      "uuuu user_id_85870_5\n",
      "1 Dashboard_user_id_85870_NoAudio_5\n",
      "k user_id_85870_5/Dashboard_user_id_85870_NoAudio_5\n",
      "uuuu user_id_86433_5\n",
      "1 Dashboard_user_id_86433_NoAudio_5\n",
      "k user_id_86433_5/Dashboard_user_id_86433_NoAudio_5\n",
      "uuuu user_id_79023_7\n",
      "1 Dashboard_user_id_79023_NoAudio_7\n",
      "k user_id_79023_7/Dashboard_user_id_79023_NoAudio_7\n",
      "uuuu user_id_46844_7\n",
      "1 Dashboard_user_id_46844_NoAudio_7\n",
      "k user_id_46844_7/Dashboard_user_id_46844_NoAudio_7\n",
      "uuuu user_id_61302_9\n",
      "1 Dashboard_user_id_61302_NoAudio_9\n",
      "k user_id_61302_9/Dashboard_user_id_61302_NoAudio_9\n",
      "uuuu user_id_63513_7\n",
      "1 Dashboard_user_id_63513_NoAudio_7\n",
      "k user_id_63513_7/Dashboard_user_id_63513_NoAudio_7\n",
      "uuuu user_id_83323_5\n",
      "1 Dashboard_user_id_83323_NoAudio_5\n",
      "k user_id_83323_5/Dashboard_user_id_83323_NoAudio_5\n",
      "uuuu user_id_69039_7\n",
      "1 Dashboard_user_id_69039_NoAudio_7\n",
      "k user_id_69039_7/Dashboard_user_id_69039_NoAudio_7\n",
      "uuuu user_id_28557_7\n",
      "1 Dashboard_user_id_28557_NoAudio_7\n",
      "k user_id_28557_7/Dashboard_user_id_28557_NoAudio_7\n",
      "uuuu user_id_87903_7\n",
      "1 Dashboard_user_id_87903_NoAudio_7\n",
      "k user_id_87903_7/Dashboard_user_id_87903_NoAudio_7\n",
      "uuuu user_id_47457_7\n",
      "1 Dashboard_user_id_47457_NoAudio_7\n",
      "k user_id_47457_7/Dashboard_user_id_47457_NoAudio_7\n",
      "uuuu user_id_20507_7\n",
      "1 Dashboard_user_id_20507_NoAudio_7\n",
      "k user_id_20507_7/Dashboard_user_id_20507_NoAudio_7\n",
      "uuuu user_id_86952_11\n",
      "1 Dashboard_user_id_86952_NoAudio_11\n",
      "k user_id_86952_11/Dashboard_user_id_86952_NoAudio_11\n",
      "uuuu user_id_63513_5\n",
      "1 Dashboard_user_id_63513_NoAudio_5\n",
      "k user_id_63513_5/Dashboard_user_id_63513_NoAudio_5\n",
      "uuuu user_id_64003_5\n",
      "1 Dashboard_user_id_64003_NoAudio_5\n",
      "k user_id_64003_5/Dashboard_user_id_64003_NoAudio_5\n",
      "uuuu user_id_42711_5\n",
      "1 Dashboard_user_id_42711_NoAudio_5\n",
      "k user_id_42711_5/Dashboard_user_id_42711_NoAudio_5\n",
      "uuuu user_id_46856_5\n",
      "1 Dashboard_user_id_46856_NoAudio_5\n",
      "k user_id_46856_5/Dashboard_user_id_46856_NoAudio_5\n",
      "uuuu user_id_13522_5\n",
      "1 Dashboard_user_id_13522_NoAudio_5\n",
      "k user_id_13522_5/Dashboard_user_id_13522_NoAudio_5\n",
      "uuuu user_id_30932_7\n",
      "1 Dashboard_user_id_30932_NoAudio_7\n",
      "k user_id_30932_7/Dashboard_user_id_30932_NoAudio_7\n",
      "uuuu user_id_20090_5\n",
      "1 Dashboard_user_id_20090_NoAudio_5\n",
      "k user_id_20090_5/Dashboard_user_id_20090_NoAudio_5\n",
      "uuuu user_id_84935_5\n",
      "1 Dashboard_user_id_84935_NoAudio_5\n",
      "k user_id_84935_5/Dashboard_user_id_84935_NoAudio_5\n",
      "uuuu user_id_25077_5\n",
      "1 Dashboard_user_id_25077_NoAudio_5\n",
      "k user_id_25077_5/Dashboard_user_id_25077_NoAudio_5\n",
      "uuuu user_id_36305_3\n",
      "1 Dashboard_user_id_36305_NoAudio_3\n",
      "k user_id_36305_3/Dashboard_user_id_36305_NoAudio_3\n",
      "uuuu user_id_20507_5\n",
      "1 Dashboard_user_id_20507_NoAudio_5\n",
      "k user_id_20507_5/Dashboard_user_id_20507_NoAudio_5\n",
      "uuuu user_id_46856_7\n",
      "1 Dashboard_user_id_46856_NoAudio_7\n",
      "k user_id_46856_7/Dashboard_user_id_46856_NoAudio_7\n",
      "uuuu user_id_60768_5\n",
      "1 Dashboard_user_id_60768_NoAudio_5\n",
      "k user_id_60768_5/Dashboard_user_id_60768_NoAudio_5\n",
      "uuuu user_id_20090_7\n",
      "1 Dashboard_user_id_20090_NoAudio_7\n",
      "k user_id_20090_7/Dashboard_user_id_20090_NoAudio_7\n",
      "uuuu user_id_86356_5\n",
      "1 Dashboard_user_id_86356_NoAudio_5\n",
      "k user_id_86356_5/Dashboard_user_id_86356_NoAudio_5\n",
      "uuuu user_id_20931_5\n",
      "1 Dashboard_user_id_20931_NoAudio_5\n",
      "k user_id_20931_5/Dashboard_user_id_20931_NoAudio_5\n",
      "uuuu user_id_86433_7\n",
      "1 Dashboard_user_id_86433_NoAudio_7\n",
      "k user_id_86433_7/Dashboard_user_id_86433_NoAudio_7\n",
      "uuuu user_id_61497_5\n",
      "1 Dashboard_user_id_61497_NoAudio_5\n",
      "k user_id_61497_5/Dashboard_user_id_61497_NoAudio_5\n",
      "uuuu user_id_57207_3\n",
      "1 Dashboard_user_id_57207_NoAudio_3\n",
      "k user_id_57207_3/Dashboard_user_id_57207_NoAudio_3\n",
      "uuuu user_id_25432_5\n",
      "1 Dashboard_user_id_25432_NoAudio_5\n",
      "k user_id_25432_5/Dashboard_user_id_25432_NoAudio_5\n",
      "uuuu user_id_86356_7\n",
      "1 Dashboard_user_id_86356_NoAudio_7\n",
      "k user_id_86356_7/Dashboard_user_id_86356_NoAudio_7\n",
      "uuuu user_id_47158_7\n",
      "1 Dashboard_user_id_47158_NoAudio_7\n",
      "k user_id_47158_7/Dashboard_user_id_47158_NoAudio_7\n",
      "uuuu user_id_39367_7\n",
      "1 Dashboard_user_id_39367_NoAudio_7\n",
      "k user_id_39367_7/Dashboard_user_id_39367_NoAudio_7\n",
      "uuuu user_id_71436_7\n",
      "1 Dashboard_user_id_71436_NoAudio_7\n",
      "k user_id_71436_7/Dashboard_user_id_71436_NoAudio_7\n",
      "uuuu user_id_61962_7\n",
      "1 Dashboard_user_id_61962_NoAudio_7\n",
      "k user_id_61962_7/Dashboard_user_id_61962_NoAudio_7\n",
      "uuuu user_id_59359_7\n",
      "1 Dashboard_user_id_59359_NoAudio_7\n",
      "k user_id_59359_7/Dashboard_user_id_59359_NoAudio_7\n",
      "uuuu user_id_36305_5\n",
      "1 Dashboard_user_id_36305_NoAudio_5\n",
      "k user_id_36305_5/Dashboard_user_id_36305_NoAudio_5\n",
      "uuuu user_id_71720_5\n",
      "1 Dashboard_user_id_71720_NoAudio_5\n",
      "k user_id_71720_5/Dashboard_user_id_71720_NoAudio_5\n",
      "uuuu user_id_71436_5\n",
      "1 Dashboard_user_id_71436_NoAudio_5\n",
      "k user_id_71436_5/Dashboard_user_id_71436_NoAudio_5\n",
      "uuuu user_id_59359_5\n",
      "1 Dashboard_user_id_59359_NoAudio_5\n",
      "k user_id_59359_5/Dashboard_user_id_59359_NoAudio_5\n",
      "uuuu user_id_33682_5\n",
      "1 Dashboard_user_id_33682_NoAudio_5\n",
      "k user_id_33682_5/Dashboard_user_id_33682_NoAudio_5\n",
      "uuuu user_id_31903_5\n",
      "1 Dashboard_user_id_31903_NoAudio_5\n",
      "k user_id_31903_5/Dashboard_user_id_31903_NoAudio_5\n",
      "uuuu user_id_35418_7\n",
      "1 Dashboard_user_id_35418_NoAudio_7\n",
      "k user_id_35418_7/Dashboard_user_id_35418_NoAudio_7\n",
      "uuuu user_id_41850_7\n",
      "1 Dashboard_user_id_41850_NoAudio_7\n",
      "k user_id_41850_7/Dashboard_user_id_41850_NoAudio_7\n",
      "uuuu user_id_78052_9\n",
      "1 Dashboard_user_id_78052_NoAudio_9\n",
      "k user_id_78052_9/Dashboard_user_id_78052_NoAudio_9\n",
      "uuuu user_id_83756_7\n",
      "1 Dashboard_user_id_83756_NoAudio_7\n",
      "k user_id_83756_7/Dashboard_user_id_83756_NoAudio_7\n",
      "uuuu user_id_59014_5\n",
      "1 Dashboard_user_id_59014_NoAudio_5\n",
      "k user_id_59014_5/Dashboard_user_id_59014_NoAudio_5\n",
      "uuuu user_id_85870_7\n",
      "1 Dashboard_user_id_85870_NoAudio_7\n",
      "k user_id_85870_7/Dashboard_user_id_85870_NoAudio_7\n",
      "uuuu user_id_47457_5\n",
      "1 Dashboard_user_id_47457_NoAudio_5\n",
      "k user_id_47457_5/Dashboard_user_id_47457_NoAudio_5\n",
      "uuuu user_id_72446_7\n",
      "1 Dashboard_user_id_72446_NoAudio_7\n",
      "k user_id_72446_7/Dashboard_user_id_72446_NoAudio_7\n",
      "uuuu user_id_16080_7\n",
      "1 Dashboard_user_id_16080_NoAudio_7\n",
      "k user_id_16080_7/Dashboard_user_id_16080_NoAudio_7\n",
      "uuuu user_id_20931_7\n",
      "1 Dashboard_user_id_20931_NoAudio_7\n",
      "k user_id_20931_7/Dashboard_user_id_20931_NoAudio_7\n",
      "uuuu user_id_84935_7\n",
      "1 Dashboard_user_id_84935_NoAudio_7\n",
      "k user_id_84935_7/Dashboard_user_id_84935_NoAudio_7\n",
      "uuuu user_id_79023_5\n",
      "1 Dashboard_user_id_79023_NoAudio_5\n",
      "k user_id_79023_5/Dashboard_user_id_79023_NoAudio_5\n",
      "/media/viplab/Storage1/driver_action_recognition/raw_features/A1/valid\n",
      "uuuu user_id_99882_7\n",
      "1 Dashboard_user_id_99882_NoAudio_7\n",
      "k user_id_99882_7/Dashboard_user_id_99882_NoAudio_7\n",
      "uuuu user_id_98067_5\n",
      "1 Dashboard_user_id_98067_NoAudio_5\n",
      "k user_id_98067_5/Dashboard_user_id_98067_NoAudio_5\n",
      "uuuu user_id_98389_5\n",
      "1 Dashboard_user_id_98389_NoAudio_5\n",
      "k user_id_98389_5/Dashboard_user_id_98389_NoAudio_5\n",
      "uuuu user_id_96269_5\n",
      "1 Dashboard_user_id_96269_NoAudio_5\n",
      "k user_id_96269_5/Dashboard_user_id_96269_NoAudio_5\n",
      "uuuu user_id_96371_7\n",
      "1 Dashboard_user_id_96371_NoAudio_7\n",
      "k user_id_96371_7/Dashboard_user_id_96371_NoAudio_7\n",
      "uuuu user_id_93542_7\n",
      "1 Dashboard_user_id_93542_NoAudio_7\n",
      "k user_id_93542_7/Dashboard_user_id_93542_NoAudio_7\n",
      "uuuu user_id_99660_7\n",
      "1 Dashboard_user_id_99660_NoAudio_7\n",
      "k user_id_99660_7/Dashboard_user_id_99660_NoAudio_7\n",
      "uuuu user_id_99660_5\n",
      "1 Dashboard_user_id_99660_NoAudio_5\n",
      "k user_id_99660_5/Dashboard_user_id_99660_NoAudio_5\n",
      "uuuu user_id_99635_5\n",
      "1 Dashboard_user_id_99635_NoAudio_5\n",
      "k user_id_99635_5/Dashboard_user_id_99635_NoAudio_5\n",
      "uuuu user_id_96269_7\n",
      "1 Dashboard_user_id_96269_NoAudio_7\n",
      "k user_id_96269_7/Dashboard_user_id_96269_NoAudio_7\n",
      "uuuu user_id_98067_7\n",
      "1 Dashboard_user_id_98067_NoAudio_7\n",
      "k user_id_98067_7/Dashboard_user_id_98067_NoAudio_7\n",
      "uuuu user_id_96371_9\n",
      "1 Dashboard_user_id_96371_NoAudio_9\n",
      "k user_id_96371_9/Dashboard_user_id_96371_NoAudio_9\n",
      "uuuu user_id_98389_7\n",
      "1 Dashboard_user_id_98389_NoAudio_7\n",
      "k user_id_98389_7/Dashboard_user_id_98389_NoAudio_7\n",
      "uuuu user_id_93491_7\n",
      "1 Dashboard_user_id_93491_NoAudio_7\n",
      "k user_id_93491_7/Dashboard_user_id_93491_NoAudio_7\n",
      "uuuu user_id_93491_5\n",
      "1 Dashboard_user_id_93491_NoAudio_5\n",
      "k user_id_93491_5/Dashboard_user_id_93491_NoAudio_5\n",
      "uuuu user_id_99882_5\n",
      "1 Dashboard_user_id_99882_NoAudio_5\n",
      "k user_id_99882_5/Dashboard_user_id_99882_NoAudio_5\n",
      "uuuu user_id_99635_7\n",
      "1 Dashboard_user_id_99635_NoAudio_7\n",
      "k user_id_99635_7/Dashboard_user_id_99635_NoAudio_7\n",
      "uuuu user_id_93542_5\n",
      "1 Dashboard_user_id_93542_NoAudio_5\n",
      "k user_id_93542_5/Dashboard_user_id_93542_NoAudio_5\n",
      "120\n",
      "18\n",
      "train 2\n",
      "valid 2\n",
      "train\n",
      "Concatenated features: torch.Size([16, 300, 6144])\n",
      "Labels: torch.Size([16, 300])\n",
      "valid\n",
      "Concatenated features: torch.Size([16, 300, 6144])\n",
      "Labels: torch.Size([16, 300])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import re\n",
    "from mamba_ssm import Mamba\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# skip_ids = [16700, 38159, 59359]\n",
    "train_features_root = '/media/viplab/Storage1/driver_action_recognition/raw_features/A1/train'\n",
    "train_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "validation_features_root = '/media/viplab/Storage1/driver_action_recognition/raw_features/A1/valid'\n",
    "validation_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "num_epochs = 100\n",
    "weights_save_path = \"mamba_weights_6144_boundary\"\n",
    "\n",
    "\n",
    "class MultiViewFeatureDataset(Dataset):\n",
    "    def __init__(self, features_root, labels_root, views=(\"Dashboard\", \"Rear_view\", \"Right_side_window\")):\n",
    "        self.features_root = features_root\n",
    "        self.labels_root = labels_root\n",
    "        self.views = views\n",
    "        # self.skip_ids = ['16700', '38159', '59359']\n",
    "        self.sample_keys = []\n",
    "        print(features_root)\n",
    "        for user_folder in os.listdir(features_root):\n",
    "            # for i in self.skip_ids:\n",
    "            #     if i in user_folder:\n",
    "            #         continue\n",
    "            print('uuuu', user_folder)\n",
    "            user_path = os.path.join(features_root, user_folder)\n",
    "            # print(user_path)\n",
    "            if not os.path.isdir(user_path):\n",
    "                continue\n",
    "            for file in os.listdir(user_path):\n",
    "                # print('f', file)\n",
    "                if file.startswith(\"Dash\") and file.endswith(\".npy\"):\n",
    "                    print('1', os.path.splitext(file)[0])\n",
    "                    key = os.path.join(user_folder, os.path.splitext(file)[0]) \n",
    "                    print('k', key) # e.g. user_001_1/dash_1\n",
    "                    self.sample_keys.append(key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.sample_keys[idx]\n",
    "\n",
    "        view_features = []\n",
    "        for view in self.views:\n",
    "            pp = view + '_' + \"_\".join(key.split('_')[:3]) + \"_NoAudio_\" + f\"{key.split('_')[-1]}\"\n",
    "            path = os.path.join(self.features_root, os.path.dirname(key), f\"{pp}.npy\")\n",
    "            features = np.load(path).astype(np.float32)  # [seq_len, feat_dim]\n",
    "            view_features.append(features)\n",
    "            # print('111111', features.shape, path)\n",
    "\n",
    "        min_rows = min(view_features[0].shape[0], view_features[1].shape[0], view_features[2].shape[0])\n",
    "        # Concatenate features across feature dimension\n",
    "        features_cat = np.concatenate((view_features[0][:min_rows, :], view_features[1][:min_rows, :], view_features[2][:min_rows, :]), axis=1)  # [seq_len, total_feat_dim]\n",
    "        label_path = os.path.join(self.labels_root, os.path.dirname(key)+ \".npy\")\n",
    "        labels = np.load(label_path).astype(np.int64)  # [seq_len]\n",
    "        # print(features_cat.shape)\n",
    "        return features_cat, labels\n",
    "\n",
    "t_dataset = MultiViewFeatureDataset(\n",
    "    features_root= train_features_root,\n",
    "    labels_root= train_labels_root\n",
    ")\n",
    "\n",
    "v_dataset = MultiViewFeatureDataset(\n",
    "    features_root= validation_features_root,\n",
    "    labels_root= validation_labels_root\n",
    ")\n",
    "print(len(t_dataset))\n",
    "print(len(v_dataset))\n",
    "\n",
    "class ChunkedVideoDataset(Dataset):\n",
    "    def __init__(self, base_dataset, chunk_size=100, stride=50):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.chunk_size = chunk_size\n",
    "        self.stride = stride\n",
    "        self.index_map = []  # (video_idx, start_frame)\n",
    "\n",
    "        for video_idx in range(len(base_dataset)):\n",
    "            features, labels = base_dataset[video_idx]\n",
    "            video_len = features.shape[0]\n",
    "\n",
    "            for start in range(0, video_len - chunk_size + 1, stride):\n",
    "                labels_chunk = labels[start:start + chunk_size]\n",
    "\n",
    "                if labels_chunk.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                self.index_map.append((video_idx, start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_idx, start = self.index_map[idx]\n",
    "        features, labels = self.base_dataset[video_idx]\n",
    "        features_chunk = features[start:start+self.chunk_size]\n",
    "        labels_chunk = labels[start:start+self.chunk_size]\n",
    "        return features_chunk, labels_chunk\n",
    "\n",
    "train_dataset = ChunkedVideoDataset(t_dataset, chunk_size=300, stride=75)\n",
    "valid_dataset = ChunkedVideoDataset(v_dataset, chunk_size=300, stride=300)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('train', len(i))\n",
    "    break\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('valid', len(i))\n",
    "    break\n",
    "\n",
    "for features, labels in train_loader:\n",
    "    print('train')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n",
    "for features, labels in valid_loader:\n",
    "    print('valid')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4232fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "# for epoch in range(num_epochs):\n",
    "#     for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "#         features = features.to(device)  # [B, 50, 6144]\n",
    "#         labels = labels.to(device)      # [B, 50]\n",
    "#         print(labels)\n",
    "#         true_boundaries = extract_boundaries_from_labels(labels)\n",
    "#         print(true_boundaries)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc27176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2eccf14",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "nonzero() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      2\u001b[0m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mextract_boundaries_from_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mextract_boundaries_from_labels\u001b[0;34m(labels, background_class)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[1;32m      6\u001b[0m     action_mask \u001b[38;5;241m=\u001b[39m labels[b] \u001b[38;5;241m!=\u001b[39m background_class\n\u001b[0;32m----> 7\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43maction_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# print(action_mask, indices)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: nonzero() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "labels = np.array([[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,8,8,8,8,8,0,0,0,6,6,6,6,6,6,6,6,0,0,0,0,4,4,4,4,4,4,4,0,0,0,0,0,0,6,6,6,6,6,0],\n",
    "[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,8,8,8,8,8,0,0,0,6,6,6,6,6,6,6,6,0,0,0,0,4,4,4,4,4,4,4,0,0,0,0,0,0,6,6,6,6,6,0],\n",
    "[1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,8,8,8,8,8,0,0,0,6,6,6,6,6,6,6,6,0,0,0,0,4,4,4,4,4,4,4,0,0,0,0,0,0,6,6,6,6,6,0]])\n",
    "extract_boundaries_from_labels(labels, background_class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0679f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6144, hidden_dim=2048, num_classes=16, seq_len=100):\n",
    "        super().__init__()\n",
    "        # self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        self.mamba_block = Mamba(\n",
    "            d_model=input_dim,\n",
    "            d_state=16,\n",
    "            d_conv=4,\n",
    "            expand=2\n",
    "        )\n",
    "        self.output_layer = nn.Linear(input_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.mamba_block(x) \n",
    "        logits = self.output_layer(x)  # [B, L, C]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33570428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def compute_per_class_accuracy(logits, labels, num_classes, ignore_index=None):\n",
    "    preds = logits.argmax(dim=-1)  # shape: [batch, seq_len]\n",
    "    labels = labels.view(-1)\n",
    "    preds = preds.view(-1)\n",
    "\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        if ignore_index is not None and cls == ignore_index:\n",
    "            continue\n",
    "        mask = labels == cls\n",
    "        class_correct[cls] += (preds[mask] == labels[mask]).sum().item()\n",
    "        class_total[cls] += mask.sum().item()\n",
    "\n",
    "    class_accuracy = {}\n",
    "    for cls in range(num_classes):\n",
    "        if ignore_index is not None and cls == ignore_index:\n",
    "            continue\n",
    "        total = class_total[cls]\n",
    "        correct = class_correct[cls]\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        class_accuracy[cls] = acc\n",
    "\n",
    "    return class_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2187fdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaSequenceClassifier(\n",
       "  (mamba_block): Mamba(\n",
       "    (in_proj): Linear(in_features=6144, out_features=24576, bias=False)\n",
       "    (conv1d): Conv1d(12288, 12288, kernel_size=(4,), stride=(1,), padding=(3,), groups=12288)\n",
       "    (act): SiLU()\n",
       "    (x_proj): Linear(in_features=12288, out_features=416, bias=False)\n",
       "    (dt_proj): Linear(in_features=384, out_features=12288, bias=True)\n",
       "    (out_proj): Linear(in_features=12288, out_features=6144, bias=False)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=6144, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MambaSequenceClassifier(input_dim=6144, hidden_dim=2048, num_classes=16)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-6)\n",
    "model.load_state_dict(torch.load('mamba_weights_6144_batch16/mamba_best.pth'))  # replace with actual path)\n",
    "model.eval()\n",
    "num_classes = 16  # change to your actual number of classes\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class accuracy:\n",
      "Class 1: 76.25%\n",
      "Class 2: 90.91%\n",
      "Class 3: 73.07%\n",
      "Class 4: 7.10%\n",
      "Class 5: 39.16%\n",
      "Class 6: 58.41%\n",
      "Class 7: 60.63%\n",
      "Class 8: 51.10%\n",
      "Class 9: 29.41%\n",
      "Class 10: 44.58%\n",
      "Class 11: 46.93%\n",
      "Class 12: 30.10%\n",
      "Class 13: 55.49%\n",
      "Class 14: 87.25%\n",
      "Class 15: 23.56%\n"
     ]
    }
   ],
   "source": [
    "all_logits = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in valid_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features).cuda()\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "logits = torch.cat(all_logits, dim=0)\n",
    "labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "class_acc = compute_per_class_accuracy(logits, labels, num_classes=num_classes, ignore_index=0)\n",
    "\n",
    "print(\"Per-class accuracy:\")\n",
    "for cls, acc in class_acc.items():\n",
    "    print(f\"Class {cls}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "715c56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(logits, labels, num_classes, ignore_index=None):\n",
    "    preds = logits.argmax(dim=-1).view(-1).cpu().numpy()\n",
    "    labels = labels.view(-1).cpu().numpy()\n",
    "\n",
    "    if ignore_index is not None:\n",
    "        mask = labels != ignore_index\n",
    "        preds = preds[mask]\n",
    "        labels = labels[mask]\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels,\n",
    "        preds,\n",
    "        labels=list(range(num_classes)),\n",
    "        zero_division=0  # Avoid divide-by-zero errors\n",
    "    )\n",
    "\n",
    "    metrics = {}\n",
    "    for cls in range(num_classes):\n",
    "        if ignore_index is not None and cls == ignore_index:\n",
    "            continue\n",
    "        metrics[cls] = {\n",
    "            \"precision\": precision[cls],\n",
    "            \"recall\": recall[cls],\n",
    "            \"f1\": f1[cls],\n",
    "            \"support\": support[cls],\n",
    "        }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6282fb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class metrics (ignoring class 0):\n",
      "Class 1: Precision: 99.59%, Recall: 76.25%, F1: 86.37%, Support: 320\n",
      "Class 2: Precision: 100.00%, Recall: 90.91%, F1: 95.24%, Support: 1155\n",
      "Class 3: Precision: 95.28%, Recall: 73.07%, F1: 82.71%, Support: 995\n",
      "Class 4: Precision: 96.88%, Recall: 7.10%, F1: 13.23%, Support: 1310\n",
      "Class 5: Precision: 97.56%, Recall: 39.16%, F1: 55.89%, Support: 715\n",
      "Class 6: Precision: 99.64%, Recall: 58.41%, F1: 73.65%, Support: 945\n",
      "Class 7: Precision: 58.95%, Recall: 60.63%, F1: 59.78%, Support: 315\n",
      "Class 8: Precision: 89.21%, Recall: 51.10%, F1: 64.98%, Support: 955\n",
      "Class 9: Precision: 70.22%, Recall: 29.41%, F1: 41.46%, Support: 425\n",
      "Class 10: Precision: 60.06%, Recall: 44.58%, F1: 51.18%, Support: 415\n",
      "Class 11: Precision: 79.94%, Recall: 46.93%, F1: 59.14%, Support: 1155\n",
      "Class 12: Precision: 54.48%, Recall: 30.10%, F1: 38.78%, Support: 1010\n",
      "Class 13: Precision: 83.83%, Recall: 55.49%, F1: 66.78%, Support: 355\n",
      "Class 14: Precision: 96.86%, Recall: 87.25%, F1: 91.81%, Support: 1310\n",
      "Class 15: Precision: 48.53%, Recall: 23.56%, F1: 31.72%, Support: 1405\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "num_classes = 16  # change as needed\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in valid_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "logits = torch.cat(all_logits, dim=0)\n",
    "labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "metrics = compute_metrics(logits, labels, num_classes=num_classes, ignore_index=0)\n",
    "\n",
    "print(\"Per-class metrics (ignoring class 0):\")\n",
    "for cls, values in metrics.items():\n",
    "    print(f\"Class {cls}: \"\n",
    "          f\"Precision: {values['precision']:.2%}, \"\n",
    "          f\"Recall: {values['recall']:.2%}, \"\n",
    "          f\"F1: {values['f1']:.2%}, \"\n",
    "          f\"Support: {values['support']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e376ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for features, labels in valid_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features).cuda()\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "logits = torch.cat(all_logits, dim=0)\n",
    "labels = torch.cat(all_labels, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7083526c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d6b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "\n",
    "frame_rate = 30\n",
    "decision_threshold = 0.4\n",
    "smoothing_kernel_size = 7\n",
    "positive_ratio_threshold = 0.3\n",
    "\n",
    "def rts(labels, frame_rate):\n",
    "    num_seconds = len(labels) // frame_rate\n",
    "    second_level = []\n",
    "    for i in range(num_seconds):\n",
    "        segment = labels[i * frame_rate: (i + 1) * frame_rate]\n",
    "        if len(segment) == 0:\n",
    "            continue\n",
    "        # Mode class in the second\n",
    "        vals, counts = np.unique(segment, return_counts=True)\n",
    "        second_level.append(vals[np.argmax(counts)])\n",
    "    return np.array(second_level)\n",
    "\n",
    "model.eval()\n",
    "num_classes = 16  # change as needed\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "from sklearn.metrics import classification_report\n",
    "with torch.no_grad():\n",
    "    for features, labels in valid_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features)\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        \n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "        probs = probs.cpu().numpy()\n",
    "\n",
    "        # mask = labels != 0  # Ignore instances of the specified class\n",
    "        # all_preds.append(probs[mask])\n",
    "        # all_labels.append(labels[mask])\n",
    "        all_preds.append(probs)\n",
    "        all_labels.append(labels)\n",
    "all_preds = np.concatenate(all_preds, axis = 0)\n",
    "all_labels = np.concatenate(all_labels, axis = 0)\n",
    "\n",
    "all_preds = all_preds.reshape(-1, all_preds.shape[-1])\n",
    "all_labels = all_labels.reshape(-1)\n",
    "\n",
    "smoothed_preds = np.stack([median_filter(all_preds[:, c], size = 20) for c in range(all_preds.shape[1])], axis = 1)\n",
    "frame_preds = np.argmax(smoothed_preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e3e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303681bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame_rate = 30\n",
    "decision_threshold = 0.4\n",
    "smoothing_kernel_size = 7\n",
    "positive_ratio_threshold = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d54106f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rts(labels, frame_rate):\n",
    "    num_seconds = len(labels) // frame_rate\n",
    "    second_level = []\n",
    "    for i in range(num_seconds):\n",
    "        segment = labels[i * frame_rate: (i + 1) * frame_rate]\n",
    "        if len(segment) == 0:\n",
    "            continue\n",
    "        # Mode class in the second\n",
    "        vals, counts = np.unique(segment, return_counts=True)\n",
    "        second_level.append(vals[np.argmax(counts)])\n",
    "    return np.array(second_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770081c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "num_classes = 16  # change as needed\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "from sklearn.metrics import classification_report\n",
    "with torch.no_grad():\n",
    "    for features, labels in valid_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        logits = model(features)\n",
    "        probs = torch.softmax(logits, dim = -1)\n",
    "        \n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "        probs = probs.cpu().numpy()\n",
    "\n",
    "        # mask = labels != 0  # Ignore instances of the specified class\n",
    "        # all_preds.append(probs[mask])\n",
    "        # all_labels.append(labels[mask])\n",
    "        all_preds.append(probs)\n",
    "        all_labels.append(labels)\n",
    "all_preds = np.concatenate(all_preds, axis = 0)\n",
    "all_labels = np.concatenate(all_labels, axis = 0)\n",
    "\n",
    "all_preds = all_preds.reshape(-1, all_preds.shape[-1])\n",
    "all_labels = all_labels.reshape(-1)\n",
    "\n",
    "smoothed_preds = np.stack([median_filter(all_preds[:, c], size = 20) for c in range(all_preds.shape[1])], axis = 1)\n",
    "frame_preds = np.argmax(smoothed_preds, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd2f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_preds = rts(frame_preds, 5)\n",
    "second_labels = rts(all_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "432b5f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7980,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e62e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.69      0.75        64\n",
      "           2       0.87      0.92      0.89       231\n",
      "           3       0.80      0.73      0.77       199\n",
      "           4       0.21      0.05      0.08       262\n",
      "           5       0.75      0.38      0.50       143\n",
      "           6       0.68      0.59      0.63       189\n",
      "           7       0.49      0.68      0.57        63\n",
      "           8       0.77      0.52      0.62       191\n",
      "           9       0.59      0.27      0.37        85\n",
      "          10       0.61      0.47      0.53        83\n",
      "          11       0.66      0.46      0.54       231\n",
      "          12       0.44      0.30      0.36       202\n",
      "          13       0.68      0.51      0.58        71\n",
      "          14       0.89      0.88      0.88       262\n",
      "          15       0.23      0.23      0.23       281\n",
      "\n",
      "   micro avg       0.64      0.50      0.56      2557\n",
      "   macro avg       0.63      0.51      0.55      2557\n",
      "weighted avg       0.61      0.50      0.54      2557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_to_include = [i for i in range(num_classes) if i != 0]\n",
    "\n",
    "print(classification_report(second_labels, second_preds, labels=labels_to_include))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76a76e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2557,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4849b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d4d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      5423\n",
      "           1       0.81      0.69      0.75        64\n",
      "           2       0.87      0.92      0.89       231\n",
      "           3       0.80      0.73      0.77       199\n",
      "           4       0.21      0.05      0.08       262\n",
      "           5       0.75      0.38      0.50       143\n",
      "           6       0.68      0.59      0.63       189\n",
      "           7       0.49      0.68      0.57        63\n",
      "           8       0.77      0.52      0.62       191\n",
      "           9       0.59      0.27      0.37        85\n",
      "          10       0.61      0.47      0.53        83\n",
      "          11       0.66      0.46      0.54       231\n",
      "          12       0.44      0.30      0.36       202\n",
      "          13       0.68      0.51      0.58        71\n",
      "          14       0.89      0.88      0.88       262\n",
      "          15       0.23      0.23      0.23       281\n",
      "\n",
      "    accuracy                           0.78      7980\n",
      "   macro avg       0.64      0.54      0.57      7980\n",
      "weighted avg       0.75      0.78      0.76      7980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_labels, second_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ca1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      5992\n",
      "           1       0.69      0.81      0.75        54\n",
      "           2       0.92      0.87      0.89       243\n",
      "           3       0.73      0.80      0.77       182\n",
      "           4       0.05      0.21      0.08        68\n",
      "           5       0.38      0.75      0.50        72\n",
      "           6       0.59      0.68      0.63       164\n",
      "           7       0.68      0.49      0.57        88\n",
      "           8       0.52      0.77      0.62       128\n",
      "           9       0.27      0.59      0.37        39\n",
      "          10       0.47      0.61      0.53        64\n",
      "          11       0.46      0.66      0.54       161\n",
      "          12       0.30      0.44      0.36       135\n",
      "          13       0.51      0.68      0.58        53\n",
      "          14       0.88      0.89      0.88       259\n",
      "          15       0.23      0.23      0.23       278\n",
      "\n",
      "    accuracy                           0.78      7980\n",
      "   macro avg       0.54      0.64      0.57      7980\n",
      "weighted avg       0.82      0.78      0.79      7980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_labels, second_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ba466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86      5957\n",
      "           1       0.75      0.84      0.79        57\n",
      "           2       0.91      0.89      0.90       238\n",
      "           3       0.74      0.80      0.77       183\n",
      "           4       0.06      0.22      0.09        69\n",
      "           5       0.39      0.75      0.51        75\n",
      "           6       0.59      0.70      0.64       159\n",
      "           7       0.65      0.46      0.54        89\n",
      "           8       0.52      0.75      0.62       133\n",
      "           9       0.26      0.48      0.34        46\n",
      "          10       0.45      0.52      0.48        71\n",
      "          11       0.45      0.65      0.53       159\n",
      "          12       0.30      0.41      0.34       146\n",
      "          13       0.55      0.74      0.63        53\n",
      "          14       0.88      0.89      0.88       258\n",
      "          15       0.24      0.24      0.24       287\n",
      "\n",
      "    accuracy                           0.78      7980\n",
      "   macro avg       0.54      0.63      0.57      7980\n",
      "weighted avg       0.82      0.78      0.79      7980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_labels, second_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ea83769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7980"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(second_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4164cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86      5860\n",
      "           1       0.77      0.80      0.78        61\n",
      "           2       0.91      0.88      0.90       239\n",
      "           3       0.73      0.80      0.76       183\n",
      "           4       0.06      0.22      0.10        72\n",
      "           5       0.41      0.72      0.52        81\n",
      "           6       0.60      0.69      0.64       163\n",
      "           7       0.65      0.38      0.48       107\n",
      "           8       0.51      0.68      0.58       143\n",
      "           9       0.26      0.37      0.30        60\n",
      "          10       0.47      0.54      0.50        72\n",
      "          11       0.47      0.65      0.55       168\n",
      "          12       0.30      0.40      0.34       152\n",
      "          13       0.55      0.63      0.59        62\n",
      "          14       0.88      0.87      0.87       264\n",
      "          15       0.23      0.23      0.23       293\n",
      "\n",
      "    accuracy                           0.77      7980\n",
      "   macro avg       0.54      0.61      0.56      7980\n",
      "weighted avg       0.80      0.77      0.78      7980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_preds, second_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e62a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Class 1: Precision: 99.59%, Recall: 76.25%, F1: 86.37%, Support: 320\n",
    "Class 2: Precision: 100.00%, Recall: 90.91%, F1: 95.24%, Support: 1155\n",
    "Class 3: Precision: 95.28%, Recall: 73.07%, F1: 82.71%, Support: 995\n",
    "Class 4: Precision: 96.88%, Recall: 7.10%, F1: 13.23%, Support: 1310\n",
    "Class 5: Precision: 97.56%, Recall: 39.16%, F1: 55.89%, Support: 715\n",
    "Class 6: Precision: 99.64%, Recall: 58.41%, F1: 73.65%, Support: 945\n",
    "Class 7: Precision: 58.95%, Recall: 60.63%, F1: 59.78%, Support: 315\n",
    "Class 8: Precision: 89.21%, Recall: 51.10%, F1: 64.98%, Support: 955\n",
    "Class 9: Precision: 70.22%, Recall: 29.41%, F1: 41.46%, Support: 425\n",
    "Class 10: Precision: 60.06%, Recall: 44.58%, F1: 51.18%, Support: 415\n",
    "Class 11: Precision: 79.94%, Recall: 46.93%, F1: 59.14%, Support: 1155\n",
    "Class 12: Precision: 54.48%, Recall: 30.10%, F1: 38.78%, Support: 1010\n",
    "Class 13: Precision: 83.83%, Recall: 55.49%, F1: 66.78%, Support: 355\n",
    "Class 14: Precision: 96.86%, Recall: 87.25%, F1: 91.81%, Support: 1310\n",
    "Class 15: Precision: 48.53%, Recall: 23.56%, F1: 31.72%, Support: 1405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea7e38d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "18\n",
      "train 2\n",
      "valid 2\n",
      "train\n",
      "Concatenated features: torch.Size([8, 300, 102])\n",
      "Labels: torch.Size([8, 300])\n",
      "valid\n",
      "Concatenated features: torch.Size([8, 300, 102])\n",
      "Labels: torch.Size([8, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|| 429/429 [02:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -  Training Loss: 556503.6836 - Accuracy: 7.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 19.58%\n",
      "Epoch 1 - Validation Loss: 197672.4660 - Accuracy: 19.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|| 429/429 [02:45<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -  Training Loss: 158333.3511 - Accuracy: 16.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 27.01%\n",
      "Epoch 2 - Validation Loss: 92096.5593 - Accuracy: 27.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|| 429/429 [02:44<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -  Training Loss: 80720.7606 - Accuracy: 23.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 31.27%\n",
      "Epoch 3 - Validation Loss: 53399.5597 - Accuracy: 31.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|| 429/429 [02:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -  Training Loss: 48893.6573 - Accuracy: 27.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 34.01%\n",
      "Epoch 4 - Validation Loss: 33713.1264 - Accuracy: 34.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|| 429/429 [02:42<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -  Training Loss: 32223.4761 - Accuracy: 29.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 35.35%\n",
      "Epoch 5 - Validation Loss: 22970.0344 - Accuracy: 35.35%\n",
      "Model saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|| 429/429 [02:43<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -  Training Loss: 22441.0810 - Accuracy: 30.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Validation Loss: 16311.8316 - Accuracy: 35.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|| 429/429 [02:42<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -  Training Loss: 16055.5009 - Accuracy: 31.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 35.51%\n",
      "Epoch 7 - Validation Loss: 11823.9807 - Accuracy: 35.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|| 429/429 [02:42<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -  Training Loss: 11660.4478 - Accuracy: 31.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Validation Loss: 8855.6256 - Accuracy: 35.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|| 429/429 [02:42<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -  Training Loss: 8645.4002 - Accuracy: 31.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Validation Loss: 6694.6798 - Accuracy: 34.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -  Training Loss: 6450.4355 - Accuracy: 31.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Validation Loss: 5107.1976 - Accuracy: 34.55%\n",
      "Model saved at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|| 429/429 [02:48<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -  Training Loss: 4838.3306 - Accuracy: 31.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Validation Loss: 3889.1791 - Accuracy: 34.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -  Training Loss: 3639.0284 - Accuracy: 31.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Validation Loss: 2953.1020 - Accuracy: 34.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -  Training Loss: 2733.6442 - Accuracy: 31.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Validation Loss: 2270.6568 - Accuracy: 34.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -  Training Loss: 2065.0401 - Accuracy: 31.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 36.58%\n",
      "Epoch 14 - Validation Loss: 1749.3224 - Accuracy: 36.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -  Training Loss: 1565.9544 - Accuracy: 32.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 40.33%\n",
      "Epoch 15 - Validation Loss: 1344.8858 - Accuracy: 40.33%\n",
      "Model saved at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -  Training Loss: 1207.5348 - Accuracy: 34.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 44.55%\n",
      "Epoch 16 - Validation Loss: 1046.1406 - Accuracy: 44.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -  Training Loss: 925.5480 - Accuracy: 35.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 46.81%\n",
      "Epoch 17 - Validation Loss: 823.9498 - Accuracy: 46.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -  Training Loss: 726.6182 - Accuracy: 36.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 49.60%\n",
      "Epoch 18 - Validation Loss: 658.2621 - Accuracy: 49.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -  Training Loss: 569.4438 - Accuracy: 38.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 51.43%\n",
      "Epoch 19 - Validation Loss: 523.3839 - Accuracy: 51.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -  Training Loss: 445.7380 - Accuracy: 39.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 52.88%\n",
      "Epoch 20 - Validation Loss: 421.2691 - Accuracy: 52.88%\n",
      "Model saved at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 -  Training Loss: 351.3379 - Accuracy: 41.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 54.21%\n",
      "Epoch 21 - Validation Loss: 339.7896 - Accuracy: 54.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 -  Training Loss: 276.3401 - Accuracy: 41.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 54.91%\n",
      "Epoch 22 - Validation Loss: 278.0471 - Accuracy: 54.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 -  Training Loss: 221.6904 - Accuracy: 42.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 55.60%\n",
      "Epoch 23 - Validation Loss: 230.7187 - Accuracy: 55.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 -  Training Loss: 177.3774 - Accuracy: 43.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 56.34%\n",
      "Epoch 24 - Validation Loss: 191.0626 - Accuracy: 56.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 -  Training Loss: 141.1742 - Accuracy: 43.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 56.88%\n",
      "Epoch 25 - Validation Loss: 161.2149 - Accuracy: 56.88%\n",
      "Model saved at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 -  Training Loss: 112.5787 - Accuracy: 43.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 58.23%\n",
      "Epoch 26 - Validation Loss: 135.8949 - Accuracy: 58.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 -  Training Loss: 94.4103 - Accuracy: 43.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Validation Loss: 115.8763 - Accuracy: 58.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|| 429/429 [02:42<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 -  Training Loss: 74.7427 - Accuracy: 43.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 - Validation Loss: 98.1673 - Accuracy: 58.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 -  Training Loss: 62.9902 - Accuracy: 42.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 - Validation Loss: 84.2257 - Accuracy: 58.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 -  Training Loss: 49.0652 - Accuracy: 42.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 - Validation Loss: 73.0804 - Accuracy: 57.58%\n",
      "Model saved at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|| 429/429 [02:41<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 -  Training Loss: 41.5165 - Accuracy: 41.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 - Validation Loss: 64.3538 - Accuracy: 57.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 -  Training Loss: 33.2044 - Accuracy: 42.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 - Validation Loss: 56.0605 - Accuracy: 56.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 -  Training Loss: 27.6888 - Accuracy: 44.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 - Validation Loss: 50.2124 - Accuracy: 56.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 -  Training Loss: 22.9633 - Accuracy: 46.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 59.02%\n",
      "Epoch 34 - Validation Loss: 44.1731 - Accuracy: 59.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|| 429/429 [02:41<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 -  Training Loss: 19.2221 - Accuracy: 49.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 61.19%\n",
      "Epoch 35 - Validation Loss: 40.0314 - Accuracy: 61.19%\n",
      "Model saved at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|| 429/429 [02:52<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 -  Training Loss: 16.3651 - Accuracy: 51.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 62.13%\n",
      "Epoch 36 - Validation Loss: 35.9925 - Accuracy: 62.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 -  Training Loss: 14.0214 - Accuracy: 53.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 62.85%\n",
      "Epoch 37 - Validation Loss: 33.2537 - Accuracy: 62.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 -  Training Loss: 11.8705 - Accuracy: 55.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 63.23%\n",
      "Epoch 38 - Validation Loss: 29.5935 - Accuracy: 63.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 -  Training Loss: 9.9327 - Accuracy: 57.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:05<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 63.73%\n",
      "Epoch 39 - Validation Loss: 26.8527 - Accuracy: 63.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 -  Training Loss: 8.7390 - Accuracy: 59.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 64.36%\n",
      "Epoch 40 - Validation Loss: 24.7523 - Accuracy: 64.36%\n",
      "Model saved at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 -  Training Loss: 7.4696 - Accuracy: 60.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 64.68%\n",
      "Epoch 41 - Validation Loss: 23.1088 - Accuracy: 64.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 -  Training Loss: 6.6998 - Accuracy: 61.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 64.85%\n",
      "Epoch 42 - Validation Loss: 21.9198 - Accuracy: 64.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 -  Training Loss: 6.0591 - Accuracy: 62.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 65.10%\n",
      "Epoch 43 - Validation Loss: 21.0459 - Accuracy: 65.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 -  Training Loss: 5.2891 - Accuracy: 63.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 65.40%\n",
      "Epoch 44 - Validation Loss: 18.9421 - Accuracy: 65.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 -  Training Loss: 4.5627 - Accuracy: 63.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 65.46%\n",
      "Epoch 45 - Validation Loss: 18.5538 - Accuracy: 65.46%\n",
      "Model saved at epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 -  Training Loss: 4.3031 - Accuracy: 64.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 65.62%\n",
      "Epoch 46 - Validation Loss: 17.7276 - Accuracy: 65.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 -  Training Loss: 3.9693 - Accuracy: 64.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 65.85%\n",
      "Epoch 47 - Validation Loss: 16.8299 - Accuracy: 65.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|| 429/429 [02:41<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 -  Training Loss: 3.6353 - Accuracy: 64.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 66.26%\n",
      "Epoch 48 - Validation Loss: 15.4007 - Accuracy: 66.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|| 429/429 [02:41<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 -  Training Loss: 3.3099 - Accuracy: 65.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 66.66%\n",
      "Epoch 49 - Validation Loss: 14.5974 - Accuracy: 66.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|| 429/429 [02:37<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 -  Training Loss: 3.0558 - Accuracy: 65.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 - Validation Loss: 14.3408 - Accuracy: 66.64%\n",
      "Model saved at epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|| 429/429 [02:37<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 -  Training Loss: 2.9588 - Accuracy: 65.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 66.87%\n",
      "Epoch 51 - Validation Loss: 13.1136 - Accuracy: 66.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|| 429/429 [02:38<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 -  Training Loss: 2.8956 - Accuracy: 65.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 66.97%\n",
      "Epoch 52 - Validation Loss: 13.1510 - Accuracy: 66.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|| 429/429 [02:37<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 -  Training Loss: 2.6943 - Accuracy: 65.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.20%\n",
      "Epoch 53 - Validation Loss: 12.5435 - Accuracy: 67.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|| 429/429 [02:37<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 -  Training Loss: 2.5629 - Accuracy: 65.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.24%\n",
      "Epoch 54 - Validation Loss: 12.0117 - Accuracy: 67.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 -  Training Loss: 2.4558 - Accuracy: 65.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.32%\n",
      "Epoch 55 - Validation Loss: 11.3744 - Accuracy: 67.32%\n",
      "Model saved at epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 -  Training Loss: 2.2489 - Accuracy: 65.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.50%\n",
      "Epoch 56 - Validation Loss: 10.3918 - Accuracy: 67.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|| 429/429 [02:36<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 -  Training Loss: 2.2775 - Accuracy: 66.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.66%\n",
      "Epoch 57 - Validation Loss: 10.2133 - Accuracy: 67.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 -  Training Loss: 2.1342 - Accuracy: 66.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.73%\n",
      "Epoch 58 - Validation Loss: 10.2918 - Accuracy: 67.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|| 429/429 [02:37<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 -  Training Loss: 2.1214 - Accuracy: 66.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.89%\n",
      "Epoch 59 - Validation Loss: 9.8805 - Accuracy: 67.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 -  Training Loss: 2.0289 - Accuracy: 66.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.90%\n",
      "Epoch 60 - Validation Loss: 9.9233 - Accuracy: 67.90%\n",
      "Model saved at epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 -  Training Loss: 1.9670 - Accuracy: 66.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.94%\n",
      "Epoch 61 - Validation Loss: 9.3090 - Accuracy: 67.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 -  Training Loss: 1.9402 - Accuracy: 66.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.95%\n",
      "Epoch 62 - Validation Loss: 8.6018 - Accuracy: 67.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 -  Training Loss: 1.8833 - Accuracy: 66.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.95%\n",
      "Epoch 63 - Validation Loss: 9.0889 - Accuracy: 67.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 -  Training Loss: 1.8237 - Accuracy: 66.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 67.98%\n",
      "Epoch 64 - Validation Loss: 8.6892 - Accuracy: 67.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 -  Training Loss: 1.8809 - Accuracy: 66.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 - Validation Loss: 8.6043 - Accuracy: 67.98%\n",
      "Model saved at epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|| 429/429 [02:45<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 -  Training Loss: 1.8208 - Accuracy: 66.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.00%\n",
      "Epoch 66 - Validation Loss: 8.2806 - Accuracy: 68.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 -  Training Loss: 1.7446 - Accuracy: 66.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.01%\n",
      "Epoch 67 - Validation Loss: 7.8826 - Accuracy: 68.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 -  Training Loss: 1.7115 - Accuracy: 66.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.03%\n",
      "Epoch 68 - Validation Loss: 7.8021 - Accuracy: 68.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|| 429/429 [02:39<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 -  Training Loss: 1.7720 - Accuracy: 66.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.04%\n",
      "Epoch 69 - Validation Loss: 7.8205 - Accuracy: 68.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|| 429/429 [02:48<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 -  Training Loss: 1.7051 - Accuracy: 66.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 - Validation Loss: 7.6453 - Accuracy: 68.00%\n",
      "Model saved at epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|| 429/429 [02:37<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 -  Training Loss: 1.6735 - Accuracy: 66.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 - Validation Loss: 7.6523 - Accuracy: 68.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 -  Training Loss: 1.6457 - Accuracy: 66.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.05%\n",
      "Epoch 72 - Validation Loss: 7.1547 - Accuracy: 68.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|| 429/429 [02:44<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 -  Training Loss: 1.6688 - Accuracy: 66.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 - Validation Loss: 7.1729 - Accuracy: 68.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|| 429/429 [02:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 -  Training Loss: 1.6468 - Accuracy: 66.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 - Validation Loss: 7.0800 - Accuracy: 68.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 -  Training Loss: 1.6736 - Accuracy: 66.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 - Validation Loss: 6.6154 - Accuracy: 68.04%\n",
      "Model saved at epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 -  Training Loss: 1.6353 - Accuracy: 66.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 - Validation Loss: 6.3801 - Accuracy: 68.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|| 429/429 [02:42<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 -  Training Loss: 1.6450 - Accuracy: 66.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 - Validation Loss: 6.2189 - Accuracy: 68.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|| 429/429 [02:43<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 -  Training Loss: 1.6658 - Accuracy: 66.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.05%\n",
      "Epoch 78 - Validation Loss: 6.2260 - Accuracy: 68.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 -  Training Loss: 1.5858 - Accuracy: 66.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 - Validation Loss: 6.1619 - Accuracy: 68.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|| 429/429 [02:42<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 -  Training Loss: 1.5689 - Accuracy: 66.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:10<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 - Validation Loss: 6.1149 - Accuracy: 68.01%\n",
      "Model saved at epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|| 429/429 [02:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 -  Training Loss: 1.5488 - Accuracy: 66.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.06%\n",
      "Epoch 81 - Validation Loss: 6.0360 - Accuracy: 68.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 -  Training Loss: 1.5936 - Accuracy: 66.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.07%\n",
      "Epoch 82 - Validation Loss: 5.8676 - Accuracy: 68.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|| 429/429 [02:39<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 -  Training Loss: 1.6157 - Accuracy: 66.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.09%\n",
      "Epoch 83 - Validation Loss: 5.5343 - Accuracy: 68.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 -  Training Loss: 1.5666 - Accuracy: 66.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.12%\n",
      "Epoch 84 - Validation Loss: 5.5383 - Accuracy: 68.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 -  Training Loss: 1.5378 - Accuracy: 66.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:05<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 - Validation Loss: 5.6371 - Accuracy: 68.10%\n",
      "Model saved at epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 -  Training Loss: 1.5343 - Accuracy: 66.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 - Validation Loss: 5.5882 - Accuracy: 68.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 -  Training Loss: 1.5182 - Accuracy: 66.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 - Validation Loss: 5.3152 - Accuracy: 68.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 -  Training Loss: 1.5076 - Accuracy: 66.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 - Validation Loss: 5.5529 - Accuracy: 68.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|| 429/429 [02:37<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 -  Training Loss: 1.5487 - Accuracy: 66.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.13%\n",
      "Epoch 89 - Validation Loss: 5.3394 - Accuracy: 68.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 -  Training Loss: 1.5142 - Accuracy: 66.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.15%\n",
      "Epoch 90 - Validation Loss: 5.3546 - Accuracy: 68.15%\n",
      "Model saved at epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|| 429/429 [02:38<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 -  Training Loss: 1.5223 - Accuracy: 66.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 - Validation Loss: 5.4022 - Accuracy: 68.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 -  Training Loss: 1.5105 - Accuracy: 66.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.15%\n",
      "Epoch 92 - Validation Loss: 5.2328 - Accuracy: 68.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|| 429/429 [02:39<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 -  Training Loss: 1.4888 - Accuracy: 66.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 - Validation Loss: 5.6857 - Accuracy: 68.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 -  Training Loss: 1.4761 - Accuracy: 66.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 - Validation Loss: 5.2512 - Accuracy: 68.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|| 429/429 [02:40<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 -  Training Loss: 1.4900 - Accuracy: 66.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 - Validation Loss: 4.9887 - Accuracy: 68.14%\n",
      "Model saved at epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 -  Training Loss: 1.4932 - Accuracy: 66.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 - Validation Loss: 5.2542 - Accuracy: 68.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|| 429/429 [02:39<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 -  Training Loss: 1.5194 - Accuracy: 66.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:05<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 - Validation Loss: 5.4447 - Accuracy: 68.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|| 429/429 [02:40<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 -  Training Loss: 1.4802 - Accuracy: 66.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:06<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 - Validation Loss: 5.0617 - Accuracy: 68.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|| 429/429 [02:38<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 -  Training Loss: 1.4751 - Accuracy: 66.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:05<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 68.18%\n",
      "Epoch 99 - Validation Loss: 5.4762 - Accuracy: 68.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|| 429/429 [02:08<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 -  Training Loss: 1.4821 - Accuracy: 66.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 17/17 [00:04<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 - Validation Loss: 5.6688 - Accuracy: 68.16%\n",
      "Model saved at epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import re\n",
    "from mamba_ssm import Mamba\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# skip_ids = [16700, 38159, 59359]\n",
    "train_features_root = '/media/viplab/DATADRIVE1/driver_action_recognition/pose_resnet_features_multi/A1/train'\n",
    "train_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "validation_features_root = '/media/viplab/DATADRIVE1/driver_action_recognition/pose_resnet_features_multi/A1/valid'\n",
    "validation_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "num_epochs = 100\n",
    "weights_save_path = \"mamba_weights_pose_1e-5\"\n",
    "\n",
    "\n",
    "class MultiViewFeatureDataset(Dataset):\n",
    "    def __init__(self, features_root, labels_root, views=(\"Dashboard\", \"Rear_view\", \"Right_side_window\")):\n",
    "        self.features_root = features_root\n",
    "        self.labels_root = labels_root\n",
    "        self.views = views\n",
    "        # self.skip_ids = ['16700', '38159', '59359']\n",
    "        self.sample_keys = []\n",
    "        # print(features_root)\n",
    "        for user_folder in os.listdir(features_root):\n",
    "            # for i in self.skip_ids:\n",
    "            #     if i in user_folder:\n",
    "            #         continue\n",
    "            # print('uuuu', user_folder)\n",
    "            user_path = os.path.join(features_root, user_folder)\n",
    "            # print(user_path)\n",
    "            if not os.path.isdir(user_path):\n",
    "                continue\n",
    "            for file in os.listdir(user_path):\n",
    "                # print('f', file)\n",
    "                if file.startswith(\"Dash\") and file.endswith(\".npy\"):\n",
    "                    # print('1', os.path.splitext(file)[0])\n",
    "                    key = os.path.join(user_folder, os.path.splitext(file)[0]) \n",
    "                    # print('k', key) # e.g. user_001_1/dash_1\n",
    "                    self.sample_keys.append(key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.sample_keys[idx]\n",
    "\n",
    "        view_features = []\n",
    "        for view in self.views:\n",
    "            pp = view + '_' + \"_\".join(key.split('_')[:3]) + \"_NoAudio_\" + f\"{key.split('_')[-1]}\"\n",
    "            path = os.path.join(self.features_root, os.path.dirname(key), f\"{pp}.npy\")\n",
    "            features = np.load(path).astype(np.float32)  # [seq_len, feat_dim]\n",
    "            view_features.append(features)\n",
    "            # print('111111', features.shape, path)\n",
    "\n",
    "        min_rows = min(view_features[0].shape[0], view_features[1].shape[0], view_features[2].shape[0])\n",
    "        # Concatenate features across feature dimension\n",
    "        features_cat = np.concatenate((view_features[0][:min_rows, -34:], view_features[1][:min_rows, -34:], view_features[2][:min_rows, -34:]), axis=1)  # [seq_len, total_feat_dim]\n",
    "        label_path = os.path.join(self.labels_root, os.path.dirname(key)+ \".npy\")\n",
    "        labels = np.load(label_path).astype(np.int64)  # [seq_len]\n",
    "        # print(features_cat.shape)\n",
    "        return features_cat, labels\n",
    "\n",
    "t_dataset = MultiViewFeatureDataset(\n",
    "    features_root= train_features_root,\n",
    "    labels_root= train_labels_root\n",
    ")\n",
    "\n",
    "v_dataset = MultiViewFeatureDataset(\n",
    "    features_root= validation_features_root,\n",
    "    labels_root= validation_labels_root\n",
    ")\n",
    "print(len(t_dataset))\n",
    "print(len(v_dataset))\n",
    "\n",
    "class ChunkedVideoDataset(Dataset):\n",
    "    def __init__(self, base_dataset, chunk_size=100, stride=50):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.chunk_size = chunk_size\n",
    "        self.stride = stride\n",
    "        self.index_map = []  # (video_idx, start_frame)\n",
    "\n",
    "        for video_idx in range(len(base_dataset)):\n",
    "            features, labels = base_dataset[video_idx]\n",
    "            video_len = features.shape[0]\n",
    "\n",
    "            for start in range(0, video_len - chunk_size + 1, stride):\n",
    "                labels_chunk = labels[start:start + chunk_size]\n",
    "\n",
    "                if labels_chunk.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                self.index_map.append((video_idx, start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_idx, start = self.index_map[idx]\n",
    "        features, labels = self.base_dataset[video_idx]\n",
    "        features_chunk = features[start:start+self.chunk_size]\n",
    "        labels_chunk = labels[start:start+self.chunk_size]\n",
    "        return features_chunk, labels_chunk\n",
    "\n",
    "train_dataset = ChunkedVideoDataset(t_dataset, chunk_size=300, stride=75)\n",
    "valid_dataset = ChunkedVideoDataset(v_dataset, chunk_size=300, stride=300)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('train', len(i))\n",
    "    break\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('valid', len(i))\n",
    "    break\n",
    "\n",
    "for features, labels in train_loader:\n",
    "    print('train')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n",
    "for features, labels in valid_loader:\n",
    "    print('valid')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6246, hidden_dim=2048, num_classes=16, seq_len=100):\n",
    "        super().__init__()\n",
    "        # self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        self.mamba_block = Mamba(\n",
    "            d_model=input_dim,\n",
    "            d_state=16,\n",
    "            d_conv=4,\n",
    "            expand=2\n",
    "        )\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, input_dim]\n",
    "        returns: [batch_size, seq_len, num_classes]\n",
    "        \"\"\" \n",
    "        # x = self.input_proj(x)  # -> [B, L, H]\n",
    "        x = self.mamba_block(x)  # [B, L, H]\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.output_layer(x)  # [B, L, C]\n",
    "        return logits\n",
    "    \n",
    "# class BoundaryAwareLoss(nn.Module):\n",
    "#     def __init__(self, classification_weight=1.0, localization_weight=1.0, ignore_index=None):\n",
    "#         super().__init__()\n",
    "#         self.classification_weight = classification_weight\n",
    "#         self.localization_weight = localization_weight\n",
    "#         self.ignore_index = ignore_index\n",
    "\n",
    "#     def forward(self, frame_logits, labels, pred_boundaries, true_boundaries):\n",
    "#         B, T, C = frame_logits.shape\n",
    "\n",
    "#         # Frame-wise classification loss\n",
    "#         loss_cls = F.cross_entropy(\n",
    "#             frame_logits.view(-1, C),\n",
    "#             labels.view(-1),\n",
    "#             ignore_index=self.ignore_index if self.ignore_index is not None else -100\n",
    "#         )\n",
    "\n",
    "#         # Temporal boundary regression loss (L1)\n",
    "#         loss_loc = F.l1_loss(pred_boundaries, true_boundaries)\n",
    "\n",
    "#         return self.classification_weight * loss_cls + self.localization_weight * loss_loc\n",
    "\n",
    "\n",
    "\n",
    "def train_mamba(\n",
    "    model, train_loader, val_loader, optimizer, num_epochs, weights_save_path, device,\n",
    "    num_classes=16, ignore_index=None\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_count = 0\n",
    "\n",
    "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            features = features.to(device)  # [B, 50, 6144]\n",
    "            labels = labels.to(device)      # [B, 50]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(features)        # [B, 50, num_classes]\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, num_classes),\n",
    "                labels.view(-1),\n",
    "                # ignore_index=ignore_index if ignore_index is not None else -100,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # --- Accuracy ---\n",
    "            preds = logits.argmax(dim=-1)  # [B, 50]\n",
    "            # if ignore_index is not None:\n",
    "            #     mask = labels != ignore_index\n",
    "            #     total_correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            #     total_count += mask.sum().item()\n",
    "            # else:\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_count += labels.numel()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = total_correct / total_count if total_count > 0 else 0.0\n",
    "        print(f\"Epoch {epoch+1} -  Training Loss: {avg_train_loss:.4f} - Accuracy: {train_accuracy*100:.2f}%\")\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_count = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                logits = model(features)\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, num_classes),\n",
    "                    labels.view(-1),\n",
    "                    # ignore_index=ignore_index if ignore_index is not None else -100,\n",
    "                )\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_count += labels.numel()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_count if val_count > 0 else 0.0\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            # Save the model checkpoint\n",
    "            torch.save(model.state_dict(), f\"{weights_save_path}/mamba_best.pth\")\n",
    "            print(f\"Best model saved with accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f} - Accuracy: {val_accuracy*100:.2f}%\")\n",
    "        # Save the model checkpoint\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            # Save the model checkpoint\n",
    "            torch.save(model.state_dict(), f\"{weights_save_path}/mamba_epoch_{epoch+1}.pth\")\n",
    "            print(f\"Model saved at epoch {epoch+1}\")\n",
    "\n",
    "\n",
    "model = MambaSequenceClassifier(input_dim=102, hidden_dim= 68, num_classes=16)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "train_mamba(model, train_loader, valid_loader, optimizer, num_epochs, weights_save_path, device=\"cuda\", num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "18\n",
      "train 2\n",
      "valid 2\n",
      "train\n",
      "Concatenated features: torch.Size([8, 150, 22])\n",
      "Labels: torch.Size([8, 150])\n",
      "valid\n",
      "Concatenated features: torch.Size([8, 150, 22])\n",
      "Labels: torch.Size([8, 150])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|| 432/432 [01:38<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -  Training Loss: 474348.3134 - Accuracy: 12.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:06<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 26.61%\n",
      "Epoch 1 - Validation Loss: 210369.6477 - Accuracy: 26.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|| 432/432 [01:31<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -  Training Loss: 187716.5730 - Accuracy: 20.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:06<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 28.24%\n",
      "Epoch 2 - Validation Loss: 118510.5402 - Accuracy: 28.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|| 432/432 [01:29<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -  Training Loss: 118326.7703 - Accuracy: 21.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:06<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 28.54%\n",
      "Epoch 3 - Validation Loss: 77649.9833 - Accuracy: 28.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|| 432/432 [01:38<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -  Training Loss: 80673.8606 - Accuracy: 22.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with accuracy: 28.80%\n",
      "Epoch 4 - Validation Loss: 52688.5330 - Accuracy: 28.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|| 432/432 [04:36<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -  Training Loss: 57056.0536 - Accuracy: 21.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Validation Loss: 37523.3264 - Accuracy: 27.12%\n",
      "Model saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|| 432/432 [03:10<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -  Training Loss: 42085.6241 - Accuracy: 21.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:07<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Validation Loss: 27605.7857 - Accuracy: 25.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|| 432/432 [03:52<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -  Training Loss: 32118.4018 - Accuracy: 19.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:25<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Validation Loss: 20467.8663 - Accuracy: 24.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|| 432/432 [03:55<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -  Training Loss: 25064.3649 - Accuracy: 17.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:21<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Validation Loss: 15879.8592 - Accuracy: 21.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|| 432/432 [12:06<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -  Training Loss: 19950.9981 - Accuracy: 15.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:20<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Validation Loss: 12316.4119 - Accuracy: 18.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|| 432/432 [01:53<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -  Training Loss: 16198.0521 - Accuracy: 15.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Validation Loss: 9833.9239 - Accuracy: 16.24%\n",
      "Model saved at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|| 432/432 [02:04<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -  Training Loss: 13346.7548 - Accuracy: 15.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:07<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Validation Loss: 8058.5620 - Accuracy: 17.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|| 432/432 [02:23<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -  Training Loss: 11122.2370 - Accuracy: 17.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Validation Loss: 6747.3726 - Accuracy: 21.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|| 432/432 [02:15<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -  Training Loss: 9344.0997 - Accuracy: 19.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:07<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Validation Loss: 5662.1745 - Accuracy: 24.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|| 432/432 [01:57<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -  Training Loss: 7889.4506 - Accuracy: 21.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:07<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Validation Loss: 4693.4367 - Accuracy: 24.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|| 432/432 [01:49<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -  Training Loss: 6672.8013 - Accuracy: 23.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Validation Loss: 3972.8136 - Accuracy: 23.99%\n",
      "Model saved at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|| 432/432 [02:06<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -  Training Loss: 5704.6391 - Accuracy: 22.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - Validation Loss: 3314.8255 - Accuracy: 21.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|| 432/432 [01:52<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -  Training Loss: 4909.4611 - Accuracy: 21.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 - Validation Loss: 2812.9289 - Accuracy: 18.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|| 432/432 [01:58<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -  Training Loss: 4100.4174 - Accuracy: 19.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:08<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - Validation Loss: 2350.4913 - Accuracy: 15.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|| 432/432 [01:51<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -  Training Loss: 3453.3409 - Accuracy: 16.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:10<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - Validation Loss: 1968.4330 - Accuracy: 13.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|| 432/432 [04:06<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -  Training Loss: 2922.2331 - Accuracy: 14.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:10<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 - Validation Loss: 1634.0681 - Accuracy: 11.82%\n",
      "Model saved at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|| 432/432 [14:03<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 -  Training Loss: 2420.6201 - Accuracy: 12.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:09<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 - Validation Loss: 1355.5737 - Accuracy: 11.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|| 432/432 [08:32<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 -  Training Loss: 2074.5120 - Accuracy: 10.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:21<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 - Validation Loss: 1113.6183 - Accuracy: 10.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|| 432/432 [12:50<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 -  Training Loss: 1768.5274 - Accuracy: 10.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:10<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 - Validation Loss: 927.2852 - Accuracy: 9.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|| 432/432 [10:53<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 -  Training Loss: 1458.0638 - Accuracy: 9.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:44<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 - Validation Loss: 752.4512 - Accuracy: 9.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|| 432/432 [26:41<00:00,  3.71s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 -  Training Loss: 1254.0751 - Accuracy: 9.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:10<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 - Validation Loss: 631.6634 - Accuracy: 9.39%\n",
      "Model saved at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|| 432/432 [03:49<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 -  Training Loss: 1062.2324 - Accuracy: 9.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:18<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 - Validation Loss: 527.9455 - Accuracy: 9.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|| 432/432 [17:51<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 -  Training Loss: 901.6127 - Accuracy: 9.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|| 33/33 [00:19<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 - Validation Loss: 438.3549 - Accuracy: 9.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100:  63%|   | 273/432 [13:57<10:53,  4.11s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import re\n",
    "from mamba_ssm import Mamba\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# skip_ids = [16700, 38159, 59359]\n",
    "train_features_root = '/media/viplab/DATADRIVE1/driver_action_recognition/pose_resnet_features_multi/A1/train'\n",
    "train_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "validation_features_root = '/media/viplab/DATADRIVE1/driver_action_recognition/pose_resnet_features_multi/A1/valid'\n",
    "validation_labels_root = '/home/viplab/Documents/driver_action_recognition/data_processing/array_generation/arrays'\n",
    "\n",
    "num_epochs = 100\n",
    "weights_save_path = \"mamba_weights_pose\"\n",
    "\n",
    "\n",
    "class MultiViewFeatureDataset(Dataset):\n",
    "    def __init__(self, features_root, labels_root, views=(\"Dashboard\", \"Rear_view\", \"Right_side_window\")):\n",
    "        self.features_root = features_root\n",
    "        self.labels_root = labels_root\n",
    "        self.views = views\n",
    "        # self.skip_ids = ['16700', '38159', '59359']\n",
    "        self.sample_keys = []\n",
    "        # print(features_root)\n",
    "        for user_folder in os.listdir(features_root):\n",
    "            # for i in self.skip_ids:\n",
    "            #     if i in user_folder:\n",
    "            #         continue\n",
    "            # print('uuuu', user_folder)\n",
    "            user_path = os.path.join(features_root, user_folder)\n",
    "            # print(user_path)\n",
    "            if not os.path.isdir(user_path):\n",
    "                continue\n",
    "            for file in os.listdir(user_path):\n",
    "                # print('f', file)\n",
    "                if file.startswith(\"Dash\") and file.endswith(\".npy\"):\n",
    "                    # print('1', os.path.splitext(file)[0])\n",
    "                    key = os.path.join(user_folder, os.path.splitext(file)[0]) \n",
    "                    # print('k', key) # e.g. user_001_1/dash_1\n",
    "                    self.sample_keys.append(key)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.sample_keys[idx]\n",
    "\n",
    "        view_features = []\n",
    "        for view in self.views:\n",
    "            pp = view + '_' + \"_\".join(key.split('_')[:3]) + \"_NoAudio_\" + f\"{key.split('_')[-1]}\"\n",
    "            path = os.path.join(self.features_root, os.path.dirname(key), f\"{pp}.npy\")\n",
    "            features = np.load(path).astype(np.float32)  # [seq_len, feat_dim]\n",
    "            view_features.append(features)\n",
    "            # print('111111', features.shape, path)\n",
    "\n",
    "        min_rows = min(view_features[0].shape[0], view_features[1].shape[0], view_features[2].shape[0])\n",
    "        # Concatenate features across feature dimension\n",
    "        features_cat = view_features[2][:min_rows, -34: -12] # [seq_len, total_feat_dim]\n",
    "        label_path = os.path.join(self.labels_root, os.path.dirname(key)+ \".npy\")\n",
    "        labels = np.load(label_path).astype(np.int64)  # [seq_len]\n",
    "        # print(features_cat.shape)\n",
    "        return features_cat, labels\n",
    "\n",
    "t_dataset = MultiViewFeatureDataset(\n",
    "    features_root= train_features_root,\n",
    "    labels_root= train_labels_root\n",
    ")\n",
    "\n",
    "v_dataset = MultiViewFeatureDataset(\n",
    "    features_root= validation_features_root,\n",
    "    labels_root= validation_labels_root\n",
    ")\n",
    "print(len(t_dataset))\n",
    "print(len(v_dataset))\n",
    "\n",
    "class ChunkedVideoDataset(Dataset):\n",
    "    def __init__(self, base_dataset, chunk_size=100, stride=50):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.chunk_size = chunk_size\n",
    "        self.stride = stride\n",
    "        self.index_map = []  # (video_idx, start_frame)\n",
    "\n",
    "        for video_idx in range(len(base_dataset)):\n",
    "            features, labels = base_dataset[video_idx]\n",
    "            video_len = features.shape[0]\n",
    "\n",
    "            for start in range(0, video_len - chunk_size + 1, stride):\n",
    "                labels_chunk = labels[start:start + chunk_size]\n",
    "\n",
    "                if labels_chunk.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                self.index_map.append((video_idx, start))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_idx, start = self.index_map[idx]\n",
    "        features, labels = self.base_dataset[video_idx]\n",
    "        features_chunk = features[start:start+self.chunk_size]\n",
    "        labels_chunk = labels[start:start+self.chunk_size]\n",
    "        return features_chunk, labels_chunk\n",
    "\n",
    "train_dataset = ChunkedVideoDataset(t_dataset, chunk_size=150, stride=75)\n",
    "valid_dataset = ChunkedVideoDataset(v_dataset, chunk_size=150, stride=150)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('train', len(i))\n",
    "    break\n",
    "\n",
    "for i in train_dataset:\n",
    "    print('valid', len(i))\n",
    "    break\n",
    "\n",
    "for features, labels in train_loader:\n",
    "    print('train')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n",
    "for features, labels in valid_loader:\n",
    "    print('valid')\n",
    "    print(\"Concatenated features:\", features.shape)  # [1, seq_len, total_feat_dim]\n",
    "    print(\"Labels:\", labels.shape)\n",
    "    break \n",
    "\n",
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6246, hidden_dim=2048, num_classes=16, seq_len=100):\n",
    "        super().__init__()\n",
    "        # self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        self.mamba_block = Mamba(\n",
    "            d_model=input_dim,\n",
    "            d_state=16,\n",
    "            d_conv=4,\n",
    "            expand=2\n",
    "        )\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, input_dim]\n",
    "        returns: [batch_size, seq_len, num_classes]\n",
    "        \"\"\" \n",
    "        # x = self.input_proj(x)  # -> [B, L, H]\n",
    "        x = self.mamba_block(x)  # [B, L, H]\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.output_layer(x)  # [B, L, C]\n",
    "        return logits\n",
    "    \n",
    "# class BoundaryAwareLoss(nn.Module):\n",
    "#     def __init__(self, classification_weight=1.0, localization_weight=1.0, ignore_index=None):\n",
    "#         super().__init__()\n",
    "#         self.classification_weight = classification_weight\n",
    "#         self.localization_weight = localization_weight\n",
    "#         self.ignore_index = ignore_index\n",
    "\n",
    "#     def forward(self, frame_logits, labels, pred_boundaries, true_boundaries):\n",
    "#         B, T, C = frame_logits.shape\n",
    "\n",
    "#         # Frame-wise classification loss\n",
    "#         loss_cls = F.cross_entropy(\n",
    "#             frame_logits.view(-1, C),\n",
    "#             labels.view(-1),\n",
    "#             ignore_index=self.ignore_index if self.ignore_index is not None else -100\n",
    "#         )\n",
    "\n",
    "#         # Temporal boundary regression loss (L1)\n",
    "#         loss_loc = F.l1_loss(pred_boundaries, true_boundaries)\n",
    "\n",
    "#         return self.classification_weight * loss_cls + self.localization_weight * loss_loc\n",
    "\n",
    "def train_mamba(\n",
    "    model, train_loader, val_loader, optimizer, num_epochs, weights_save_path, device,\n",
    "    num_classes=16, ignore_index=None\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_count = 0\n",
    "\n",
    "        for features, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            features = features.to(device)  # [B, 50, 6144]\n",
    "            labels = labels.to(device)      # [B, 50]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(features)        # [B, 50, num_classes]\n",
    "\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, num_classes),\n",
    "                labels.view(-1),\n",
    "                # ignore_index=ignore_index if ignore_index is not None else -100,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # --- Accuracy ---\n",
    "            preds = logits.argmax(dim=-1)  # [B, 50]\n",
    "            # if ignore_index is not None:\n",
    "            #     mask = labels != ignore_index\n",
    "            #     total_correct += (preds[mask] == labels[mask]).sum().item()\n",
    "            #     total_count += mask.sum().item()\n",
    "            # else:\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_count += labels.numel()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = total_correct / total_count if total_count > 0 else 0.0\n",
    "        print(f\"Epoch {epoch+1} -  Training Loss: {avg_train_loss:.4f} - Accuracy: {train_accuracy*100:.2f}%\")\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_count = 0\n",
    "        with torch.no_grad():\n",
    "            for features, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                logits = model(features)\n",
    "                loss = F.cross_entropy(\n",
    "                    logits.view(-1, num_classes),\n",
    "                    labels.view(-1),\n",
    "                    # ignore_index=ignore_index if ignore_index is not None else -100,\n",
    "                )\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_count += labels.numel()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = val_correct / val_count if val_count > 0 else 0.0\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            # Save the model checkpoint\n",
    "            torch.save(model.state_dict(), f\"{weights_save_path}/mamba_best.pth\")\n",
    "            print(f\"Best model saved with accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f} - Accuracy: {val_accuracy*100:.2f}%\")\n",
    "        # Save the model checkpoint\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            # Save the model checkpoint\n",
    "            torch.save(model.state_dict(), f\"{weights_save_path}/mamba_epoch_{epoch+1}.pth\")\n",
    "            print(f\"Model saved at epoch {epoch+1}\")\n",
    "\n",
    "\n",
    "model = MambaSequenceClassifier(input_dim=22, hidden_dim=14, num_classes=16)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "train_mamba(model, train_loader, valid_loader, optimizer, num_epochs, weights_save_path, device=\"cuda\", num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b299fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm import Mamba\n",
    "# input_dim = 9408\n",
    "# model = Mamba(\n",
    "#             d_model=input_dim,\n",
    "#             d_state=16,\n",
    "#             d_conv=4,\n",
    "#             expand=2\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b08d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('/media/viplab/DATADRIVE1/driver_action_recognition/split_feat_vit/train/Side/6/Right_side_window_user_id_13522_NoAudio_7_2_88.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc3b1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 196, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6765dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(15, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b46b4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92cbf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4556,  0.2571,  0.4065,  ..., -0.1371, -0.0616, -0.0349],\n",
       "        [ 0.4541,  0.2583,  0.4045,  ..., -0.1359, -0.0609, -0.0352],\n",
       "        [ 0.4553,  0.2600,  0.4060,  ..., -0.1376, -0.0624, -0.0359],\n",
       "        ...,\n",
       "        [ 0.4519,  0.2571,  0.4019,  ..., -0.1361, -0.0605, -0.0349],\n",
       "        [ 0.4519,  0.2551,  0.4019,  ..., -0.1361, -0.0608, -0.0352],\n",
       "        [ 0.4524,  0.2534,  0.4014,  ..., -0.1346, -0.0588, -0.0330]],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c026868",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d40f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.type(torch.cuda.HalfTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "894604ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4556,  0.2571,  0.4065,  ..., -0.1371, -0.0616, -0.0349],\n",
       "        [ 0.4541,  0.2583,  0.4045,  ..., -0.1359, -0.0609, -0.0352],\n",
       "        [ 0.4553,  0.2600,  0.4060,  ..., -0.1376, -0.0624, -0.0359],\n",
       "        ...,\n",
       "        [ 0.4519,  0.2571,  0.4019,  ..., -0.1361, -0.0605, -0.0349],\n",
       "        [ 0.4519,  0.2551,  0.4019,  ..., -0.1361, -0.0608, -0.0352],\n",
       "        [ 0.4524,  0.2534,  0.4014,  ..., -0.1346, -0.0588, -0.0330]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33914f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8b0a47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(15, 15, kernel_size=(16,), stride=(16,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "644874bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f1042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv1d(15, 15, kernel_size=16, stride=16).to(device).half()\n",
    "\n",
    "outputs = conv(data.unsqueeze(0))\n",
    "# data = conv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51f45ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 9408])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d60c176",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db85337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 9408])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eec5dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "996d6cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mamba(\n",
       "  (in_proj): Linear(in_features=9408, out_features=37632, bias=False)\n",
       "  (conv1d): Conv1d(18816, 18816, kernel_size=(4,), stride=(1,), padding=(3,), groups=18816)\n",
       "  (act): SiLU()\n",
       "  (x_proj): Linear(in_features=18816, out_features=620, bias=False)\n",
       "  (dt_proj): Linear(in_features=588, out_features=18816, bias=True)\n",
       "  (out_proj): Linear(in_features=18816, out_features=9408, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model.to(device).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b97f498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 9408])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a2ca3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaSequenceClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=9408, hidden_dim=2048, num_classes=16):#  input_dim=451584, hidden_dim=301056, num_classes=16\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(15, 15, kernel_size=16, stride=16)\n",
    "        self.mamba_block = Mamba(\n",
    "            d_model=input_dim,\n",
    "            d_state=16,\n",
    "            d_conv=4,\n",
    "            expand=2\n",
    "        )\n",
    "        self.fc1 = nn.Linear(input_dim,num_classes) #hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [batch_size, seq_len, input_dim]\n",
    "        returns: [batch_size, seq_len, num_classes]\n",
    "        \"\"\" \n",
    "        x = self.conv(x)\n",
    "        x = self.mamba_block(x) \n",
    "        logits = self.relu(self.fc1(x))  \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00724600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaSequenceClassifier().to(device).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc0447c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27d829e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 15, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da76f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambair2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
