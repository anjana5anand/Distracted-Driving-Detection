{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10fffdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "\n",
    "def PositionEmbedding(seq_len, emb_size):\n",
    "    embeddings = torch.ones(seq_len, emb_size)\n",
    "    for i in range(seq_len):\n",
    "        for j in range(emb_size):\n",
    "            embeddings[i][j] = np.sin(i / (pow(10000, j / emb_size))) if j % 2 == 0 else np.cos(i / (pow(10000, (j - 1) / emb_size)))\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size=224):\n",
    "        self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.rand(1, 1, emb_size))\n",
    "        self.pos_embed = nn.Parameter(PositionEmbedding((img_size // patch_size)**2 + 1, emb_size))\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.projection(x)    \n",
    "\n",
    "        cls_token = repeat(self.cls_token, ' () s e -> b s e', b=b)\n",
    "\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        return x\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, emb_size, num_head):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.num_head = num_head\n",
    "        self.key = nn.Linear(emb_size, emb_size)\n",
    "        self.value = nn.Linear(emb_size, emb_size)\n",
    "        self.query = nn.Linear(emb_size, emb_size) \n",
    "        self.att_dr = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        k = rearrange(self.key(x), 'b n (h e) -> b h n e', h=self.num_head)\n",
    "        q = rearrange(self.query(x), 'b n (h e) -> b h n e', h=self.num_head)\n",
    "        v = rearrange(self.value(x), 'b n (h e) -> b h n e', h=self.num_head)\n",
    "\n",
    "\n",
    "        wei = q@k.transpose(3,2)/self.num_head ** 0.5    \n",
    "        wei = F.softmax(wei, dim=2)\n",
    "        wei = self.att_dr(wei)\n",
    "\n",
    "        out = wei@v\n",
    "\n",
    "        out = rearrange(out, 'b h n e -> b n (h e)')\n",
    "        return out\n",
    "\n",
    "  \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(emb_size, 4*emb_size),\n",
    "            nn.Linear(4*emb_size, emb_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)\n",
    "  \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,emb_size, num_head):\n",
    "        super().__init__()\n",
    "        self.att = MultiHead(emb_size, num_head)\n",
    "        self.ll =   nn.LayerNorm(emb_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.ff = FeedForward(emb_size)\n",
    "    def forward(self, x):\n",
    "        x = x + self.dropout(self.att(self.ll(x)))  # self.att(x): x -> (b , n, emb_size) \n",
    "        x = x + self.dropout(self.ff(self.ll(x)))\n",
    "        return x\n",
    "  \n",
    "\n",
    "def random_masking(x, mask_ratio):\n",
    "        \"\"\"\n",
    "        X: (B T C) \n",
    "        random masking to create randomly shuffled unmasked patches\n",
    "        \"\"\"\n",
    "\n",
    "        B, T, D = x.shape  \n",
    "        len_keep = int(T * (1 - mask_ratio))\n",
    "        \n",
    "        # creating noise of shape (B, T) to latter generate random indices\n",
    "        noise = torch.rand(B, T, device=x.device)  \n",
    "        \n",
    "        # sorting the noise, and then ids_shuffle to keep the original indexe format\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  \n",
    "        ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "        # gathering the first few samples\n",
    "        ids_keep = ids_shuffle[:, :len_keep]\n",
    "        x = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "        # generate the binary mask: 0 is keep, 1 is remove\n",
    "        mask = torch.ones([B, T], device=x.device)\n",
    "        mask[:, :len_keep] = 0\n",
    "\n",
    "        # unshuffle to get the binary mask\n",
    "        mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "        return x, mask, ids_restore\n",
    "\n",
    "\n",
    "\n",
    "class MaskedAutoEncoder(nn.Module):\n",
    "    def __init__(self, emb_size=1024, decoder_emb_size=512, patch_size=16, num_head=16, encoder_num_layers=24, decoder_num_layers=8, in_channels=3, img_size=224):\n",
    "        super().__init__()      \n",
    "        self.patch_embed = PatchEmbedding(emb_size = emb_size)\n",
    "        self.decoder_embed = nn.Linear(emb_size, decoder_emb_size)\n",
    "        self.decoder_pos_embed = nn.Parameter(torch.zeros(1, (img_size//patch_size)**2 + 1, decoder_emb_size), requires_grad=False)\n",
    "        self.decoder_pred = nn.Linear(decoder_emb_size, patch_size**2 * in_channels, bias=True)\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, decoder_emb_size))\n",
    "        self.encoder_transformer = nn.Sequential(*[Block(emb_size, num_head) for _ in range(encoder_num_layers)])\n",
    "        self.decoder_transformer = nn.Sequential(*[Block(decoder_emb_size, num_head) for _ in range(decoder_num_layers)])\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=patch_size**2 * in_channels, kernel_size=patch_size, stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "    def encoder(self, x, mask_ratio):\n",
    "        x = self.patch_embed(x)\n",
    "    \n",
    "        cls_token = x[:, :1, :]\n",
    "        x = x[:, 1:, :] \n",
    "        \n",
    "        x, mask, restore_id = random_masking(x, mask_ratio)\n",
    "        \n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        \n",
    "        x = self.encoder_transformer(x)\n",
    "        \n",
    "        return x, mask, restore_id\n",
    "        \n",
    "    def decoder(self, x, restore_id):\n",
    "        \n",
    "        x = self.decoder_embed(x)\n",
    "        \n",
    "        mask_tokens = self.mask_token.repeat(x.shape[0], restore_id.shape[1] + 1 - x.shape[1], 1)\n",
    "        x_ = torch.cat([x[:, 1:, :], mask_tokens], dim=1) \n",
    "        x_ = torch.gather(x_, dim=1, index=restore_id.unsqueeze(-1).repeat(1, 1, x.shape[2]))  \n",
    "        x = torch.cat([x[:, :1, :], x_], dim=1)  \n",
    "\n",
    "        # add pos embed\n",
    "        x = x + self.decoder_pos_embed\n",
    "\n",
    "        x = self.decoder_transformer(x)\n",
    "\n",
    "        # predictor projection\n",
    "        x = self.decoder_pred(x)\n",
    "\n",
    "        # remove cls token\n",
    "        x = x[:, 1:, :]\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def loss(self, imgs, pred, mask):\n",
    "        \"\"\"\n",
    "        imgs: [N, 3, H, W]\n",
    "        pred: [N, L, patch*patch*3]\n",
    "        mask: [N, L], 0 is keep, 1 is remove, \n",
    "        \"\"\"\n",
    "        target = self.project(imgs)\n",
    "        \n",
    "        loss = (pred - target) ** 2\n",
    "        loss = loss.mean(dim=-1) \n",
    "    \n",
    "        loss = (loss * mask).sum() / mask.sum()  \n",
    "        return loss\n",
    "\n",
    "    def forward(self, img):\n",
    "        mask_ratio = 0.75\n",
    "\n",
    "        x, mask, restore_ids = self.encoder(img, mask_ratio)\n",
    "        pred = self.decoder(x, restore_ids) \n",
    "        loss  = self.loss(img, pred, mask) \n",
    "        return loss, pred, mask\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd3cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "x = torch.rand(1, 3, 224, 224).to(device)\n",
    "model = MaskedAutoEncoder().to(device)\n",
    "print(model(x)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f7fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada60816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f28476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9135c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a876e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedAutoEncoder(\n",
       "  (patch_embed): PatchEmbedding(\n",
       "    (projection): Sequential(\n",
       "      (0): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (1): Rearrange('b e (h) (w) -> b (h w) e')\n",
       "    )\n",
       "  )\n",
       "  (decoder_embed): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (decoder_pred): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (encoder_transformer): Sequential(\n",
       "    (0): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_transformer): Sequential(\n",
       "    (0): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (att): MultiHead(\n",
       "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (att_dr): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ll): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ff): FeedForward(\n",
       "        (ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (project): Sequential(\n",
       "    (0): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (1): Rearrange('b e (h) (w) -> b (h w) e')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49c5ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viplab/miniconda3/envs/videomae2/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, ViTMAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23e8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ac2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTMAEModel.from_pretrained('facebook/vit-mae-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df54f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('/media/viplab/Storage1/driver_action_recognition/crop_new/cut_frames_rear/class_1/user_id_25077/Rear_view_user_id_25077_5_2227.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60839267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef908e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(\"facebook/vit-mae-base\")\n",
    "inputs = image_processor(images=image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56cc839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54fac612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mohit?? lohith "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e48d1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fc8a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d181818",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv3d_weights = model.embeddings.patch_embeddings.projection.weight \n",
    "averaged_weights = conv3d_weights.mean(dim=1, keepdim=True)\n",
    "model.embeddings.patch_embeddings.projection = nn.Conv3d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
    "model.embeddings.patch_embeddings.projection.weight.data = averaged_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb62606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afca9222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTMAEModel(\n",
       "  (embeddings): ViTMAEEmbeddings(\n",
       "    (patch_embeddings): ViTMAEPatchEmbeddings(\n",
       "      (projection): Conv3d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "  )\n",
       "  (encoder): ViTMAEEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80eb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
